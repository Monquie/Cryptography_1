{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crypto notes - Stanford\n",
    "\n",
    "$\\bigoplus$$\\bigoplus$$\\bigoplus$$\\bigoplus$$\\bigoplus$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "From the introduction, really excited about: homographic encryption (computations on cipher text!)+ Zero-Knowledge proof (proving someone that I know p and q without revealing anything else than N)  \n",
    "\n",
    "# History\n",
    "\n",
    "The Building blocks of Creyptography is Symmetric ciphers:\n",
    "\n",
    "Now, the building block for securing traffic is what's called symmetric encryption systems. And we're gonna talk, in the first half of the course extensively about symmetric encryption systems. So in a symmetric encryption system, basically, the two parties, Alice and Bob, share a secret key k, which the attacker does not know. Only they know the secret key k. Now, they're gonna use a cipher which consists of these two algorithms, **E and D**. **E** is called an **encryption algorithm** and **D** is called the **decryption algorithm**. The encryption algorithm takes the message and the key as inputs, and produces a corresponding **ciphertext**. And the decryption algorithm does the opposite. It takes the ciphertext as input along with the key key and produces the corresponding message. Now, a very important point that I would like to stress. \n",
    "\n",
    "I'm only gonna say this once now and never again, but it is an extremely important point. And that is: that the algorithms **E and D**, the actual **encryption algorithms** are **publicly** known. **Adversary** knows exactly how they work. The only thing that's kept secret is the secret key **k**. Other than that everything else is completely public and it's really important to realize that you should only use algorithms that are public because those algorithms have been peer-reviewed by a very large community of hundreds of people for many, many, many years, and these algorithms only begin to be used once this community has shown that they cannot be broken, essentially. So in fact, if somebody comes to you and says, hey, I have a proprietary cipher that you might want to use, the answer usually should be that you stick to standards, to standard algorithms, and not use a proprietary cipher. In fact, there are many examples of proprietary ciphers that, as soon as they were reverse engineered, they were easily broken by simple analysis. \n",
    "\n",
    "![IMAGE](http://localhost:8888/files/Dropbox/Cryptography I/ScreenShot2017-01-23at20.41.43.jpg)\n",
    "```\n",
    "and check the path of luanching the notebook make sure the path is this way.\n",
    "```\n",
    "\n",
    "```\n",
    "![IMAGE](http://localhost:8888/files/Dropbox/00_Research_Work/E-Prescription/Screen%20Shot%202017-01-18%20at%2014.44.00.jpg)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "![image3](http://localhost:8888/files/Dropbox/00_Research_Work/E-Prescription/Notebooks/Screen%20Shot%202016-08-20%20at%203.52.08%20PM.jpg)\n",
    "\n",
    "\n",
    "![Building_BlockSymetric_Encryption](http://localhost:8888/files/Dropbox/Cryptography I/Building_BlockSymetric_Encryption.png)\n",
    "```\n",
    "\n",
    "# Use Cases\n",
    "\n",
    "## Single Use Keys (One Time Key)\n",
    "* Key is only used to encrypt one message\n",
    "* Example Encrypted Email: New key is generated for every email\n",
    "\n",
    "## Multi Use Key (Many time key)\n",
    "* Used ti encrypt multiple messages \n",
    "* Example Encrypted files on a file system: Same key used to encryot many files\n",
    "* Need more machinery than for one-time key\n",
    "\n",
    "\n",
    "\n",
    "# The Core of Cryptography \n",
    "\n",
    "* So the core of cryptography of course is secure communication that essentially consists of two parts.\n",
    "    * **The first is secured key establishment and** \n",
    "    * **Then how do we communicate securely once we have a shared key** \n",
    "\n",
    "### Cryptography does more **Digital Signature**\n",
    "* The way digital signatures work is basically by making the digital signature via function of the content being signed. So an attacker who tries to copy my signature from one document to another is not gonna succeed because the signature. On the new document is not gonna be the proper function of the data in the new document, and as a result, the signature won't verify.\n",
    "    \n",
    "### Anonymous Communication \n",
    "* Another application of cryptography that I wanted to mention, is anonymous communication. So, here, imagine user Alice wants to talk to some chat server, Bob. And, perhaps she wants to talk about a medical condition, and so she wants to do that anonymously, so that the chat server doesn't actually know who she is. Well, there's a standard method, called a mixnet, that allows Alice to communicate over the public internet with Bob through a sequence of proxies such that at the end of the communication Bob has no idea who he just talked to. The way mixnets work is basically as Alice sends her messages to Bob through a sequence of proxies, these messages get encrypted and decrypted appropriately so that Bob has no idea who he talked to and the proxies themselves don't even know that Alice is talking to Bob, or that actually who is talking to whom more generally. One interesting thing about this anonymous communication channel is, this is bi-directional. In other words, even though Bob has no idea who he's talking to, he can still respond to Alice and Alice will get those messages. Once we have anonymous communication, we can build other privacy mechanisms. And I wanna give you one example which is called anonymous digital cash. \n",
    "\n",
    "### Anonymous Cash or currency\n",
    "\n",
    "* And we'll talk about anonymous digital cash later on. Just to give you a hint, I'll say that the way we do it is basically by making sure that if Alice spends the coin once then no one knows who she is, but if she spends the coin more than once, all of a sudden, her identity is completely exposed and then she could be subject to all sorts of legal problems.\n",
    "\n",
    "### The Voting Problem\n",
    "\n",
    "* Another application of cryptography has to do with more abstract protocols, but before I speak the general result, I want to give you two examples. So the first example has to do with election systems. So here's the election problem. Suppose ... we have two parties, party zero and party one. And voters vote for these parties. So for example, this voter could have voted for party zero, this voter voted for party one. And so on. So in this election, party zero got three votes and party two got two votes. So the winner of the election, of course, is party zero. But more generally, the winner of the election is the party who receives the majority \n",
    "\n",
    "* The voters would somehow like to compute the majority of the votes, but do it in such a way such that nothing else is revealed about their individual votes. Okay? So the question is how to do that? And to do so, we're gonna introduce an election center who's gonna help us compute the majority, but keep the votes otherwise secret. And what the parties will do is they will each send the funny encryption of their votes to the election center in such a way that at the end of the election, the election center is able to compute and output the winner of the election. However, other than the winner of the election, nothing else is revealed about the individual votes. The individual votes otherwise remain completely private. Of course the election center is also gonna verify that this voter for example is allowed to vote and that the voter has only voted once. But other than that information the election center and the rest of the world learned nothing else about that voter's vote other than the result of the election\n",
    "    \n",
    "    \n",
    "    \n",
    "### The magical Cryptograohy: Google Search: privately outsourcing computation\n",
    "\n",
    "* Now, there are some applications of cryptography that I can't classify any other way other than to say that they are purely magical. Let me give you two examples of that. So the first is what's called **privately outsourcing computation**. So I'll give you an example of a Google search just to illustrate the point. So imagine Alice has a search query that she wants to issue. It turns out that there are very special encryption schemes such that Alice can send an encryption of her query to Google. And then because of the property of the encryption scheme Google can actually compute on the encrypted values without knowing what the plain texts are. So Google can actually run its massive search algorithm on the encrypted query and recover in encrypted results. Okay. Google will send the encrypted results back to Alice. Alice will decrypt and then she will receive the results. But the magic here is all Google saw was just encryptions of her queries and nothing else. And so, Google as a result has no idea what Alice just searched for and nevertheless Alice actually learned exactly what she wanted to learn. Okay so, these are magical kind of encryption schemes. They're fairly recent, this is only a new development from about two or three years ago, that allows us to compute on encrypted data, even though we don't really know what's inside the encryption. Now, before you rush off and think about implementing this, I should warn you that this is really at this point just theoretical, in the sense that running a Google search on encryption data probably would take a billion years. But nevertheless, just the fact that this is doable is already really surprising, and is already quite useful for relatively simple computations. So in fact, we'll see some applications of this later on.\n",
    "    \n",
    "### Zero Knowladge Proof\n",
    "\n",
    "* The other magical application I want to show you is what's called zero knowledge. And in particular, I'll tell you about something called the zero knowledge proof of knowledge. So here ... what happens is there's a certain number N, which Alice knows. And the way the number N was constructed is as a product of two large primes. So, imagine here we have two primes, P and Q. Each one you can think of it as like 1000 digits. And you probably know that multiplying two 1000-digit numbers is fairly easy. But if I just give you their product, figuring out their factorization into primes is actually quite difficult. And, in fact, we're gonna use the fact that factoring is difficult to build public key cryptosystems in the second half of the course. Okay, so Alice happens to have this number N, and she also knows the factorization of N. Now Bob just has the number N. He doesn't actually know the factorization. Now, the magical fact about the zero knowledge proof of knowledge, is that Alice can prove to Bob that she knows the factorization of N. Yes, you can actually give this proof to Bob, that Bob can check, and become convinced that Alice knows the factorization of N, however Bob learns nothing at all. About the factors P and Q, and this is provable. Bob absolutely learns nothing at all about the factors P and Q. And the statement actually is very, very general. This is not just about proving the factorization of N. In fact, almost any puzzle that you want to prove that you know an answer to, you can prove it is your knowledge. So if you have a crossword puzzle that you've solved. Well, maybe crosswords is not the best example. But if you have like a Sudoku puzzle, for example, that you want to prove that you've solved, you can prove it to Bob in a way that Bob would learn nothing at all about the solution, and yet Bob would be convinced that you really do have a solution to this puzzle\n",
    "    \n",
    "    \n",
    "### Historic Exmaple of Ciphers\n",
    "- Symetric Ciphers\n",
    "    - Substitution ciphers : Mapping letters where the key is a substituitiontable that basically says how to map letters in a table. (breaking by entropy attack)\n",
    "    - Caesar cipher not really a cipher, it is basically a substitution cipher where the substitution is fixed, Namely its a shiift by 3. (bad substitution cipher because no key (if you know the number of shifts, you win))How many different keys are there, assuming we have 26 letters? So, I hope all of you said that, the number of keys is 26 factorial, because, a key, a substitution key, is simply a table, a permutation of all 26 letters. The number of permutations of 26 letters, is 26 factorial. If you calculate this out, twenty-sixth factorial is about two to the 88th, which means that describing a key in a substitution cipher takes about 88 bits. So, each key is represented by about 88 bits\n",
    "    \n",
    "    \n",
    "    - Vigener cipher (have a key that's concatenated as long as there is plaintext, then take CipherText = (key + plaintext mod 26)). When we discover the key size, we can thus perform an entropy attack on every letter.\n",
    "- Rotor Motor :\n",
    "\t- Hebern: Rotor-powered substitution table -> statistical attacks\n",
    "\t- Enigma ($2^{18}$ keyspace) - broken by cipher text attacks \n",
    "\n",
    "- DES (1974, NIST standard)\n",
    "\t- $2^{56}$ keyspace -> can be bruteforced these days, not to be used anymore\n",
    "\t- blocks size 64 bits\n",
    "\n",
    "Now: AES, SALSA20\n",
    "\n",
    "# Discrete Probability \n",
    "So first let's do a quick recap of where we are. We said that the discrete probability is always defined over a finite set, which we're gonna denote by U, and typically for us, U is going to be the set of all N bit binary strings, which we denote by zero 130 N. Now a probability distribution P over this universe U is basically a function that assigns to every element in the universe a weight in the interval zero to one, such that if we sum the weight of all these elements, the sum basically sums up to one. Now we have said that subset of the universe is what called an event, and we said that probability of an event is basically the sum of all the weights of all the elements in the event and we said that probability of an event is some real numbers in the interval zero to one And I would remind everyone the basically probability of the entire universe is basically the one by the fact that sum of all the weights sums up to one. Then we define what a random variable is Formally, a random variable is a, is a function from the universe of some other sets But the thing that I want you to remember is that the random variable takes, values in some set v And, in fact, the random variable defines the distribution on this set v\n",
    "\n",
    "[Discrete Probability](https://en.wikibooks.org/wiki/High_School_Mathematics_Extensions/Discrete_Probability)\n",
    "\n",
    "Not much new material covered => See chapter in DS course for more info.\n",
    "\n",
    "Random variable, events, independence, XOR ...\n",
    "\n",
    "#### XOR \n",
    "XOR has the amazing property of always adding entropy, never removing it. \n",
    "So before we talk about XOR, let me just do a very quick review of what XOR is. So, of course, XOR of two bits means the addition of those bits, modular two. So just too kind of, make sure everybody's on the same page If we have two bits, so 0001, ten and eleven. Their XOR or the truth table of the XOR is basically just the addition modular two. As you can see, one+1 is= to two, modular two. That's=to zero. So this is the truth table for XOR And I'm always going to denote XOR by the circle with a + inside And then when I wanna apply XOR to bit strings, I apply the, addition modular two operation, bitwise. So, for example, the XOR of these two strings would be, 110, and I guess I'll let you fill out the rest of the XORs, just to make sure we're all on the same page. So of course is comes out to one, one zero one. Now, we're gonna be doing a lot of XORing in this class. In fact, there's a classical joke that the only think cryptographers know how to do is just XOR things together But I want to explain to you why we see XOR so frequently in cryptography. Basically, XOR has a very important property, and the property is the following. Suppose we have a random variable y. That's distributed arbitrarily over 01 to the n. So we know nothing about the distribution of y But now, suppose we have an independent random variable that happens to be uniformly distributed also over 01 to the n. So it's very important that x is uniform. N's independent of y. So now let's define the random variable which is the XOR of x and y. \n",
    "**Then I claim that no matter what distribution y started with, this z is always going to be a uniform, random variable. So in other words if I take an arbitrarily malicious distribution and I XOR with independent uniform random variable what I end up with is a uniform random variable. Okay and this again is kind of a key property that makes x or very useful for crypto.**\n",
    "\n",
    "\n",
    "## Birthday paradox \n",
    "\n",
    "when n = 1.2 x U^(1/2) ==> Pr[there exists two similar elements] >= 1/2\n",
    "\n",
    "# Stream ciphers\n",
    "\n",
    "## Information theoretic security \n",
    "\n",
    "A **cipher** is defined over a triple ( the key space, message space, cipher space) and does provide two functions E and D in such a way that **D(k, E(k,m)) = m.** (consistent equation)\n",
    "\n",
    "E is sometimes randomised but D is always deterministic. \n",
    "\n",
    "### OTP \n",
    "**The Vernam Cipher** is a cipher where the key is as long as the message where the cipher text is obtained by E(m,k)=(message XOR key) = cipher text and D(c,k) = c XOR k = message.\n",
    "\n",
    "Vernam is not useful in practise because if we have a secure channel to send the keys over, we could use that to send the message, so what’s the point of the cipher, right?\n",
    "\n",
    "A cipher (E,D) over (K, M, C) has **perfect secrecy** if for every two messages, m_0 and m_1 in M, length of m_0 is equal to the length of m_1 and for every c in C, Pr[E(k,m_{0}) = c] = Pr[E(k, m_{1})=c].\n",
    "Perfect secrecy means that there are no cipher text only attack!\n",
    "\n",
    "If one cipher has perfect secrecy => |K| $\\geq$ |M|, the key_length $\\geq$ message_length.\n",
    "\n",
    "\n",
    "So let me just remind you that a cypher is defined over a triple of sets called a key space, a message space, and a cypher text bare space. And a cypher is a pair of efficient algorithms called E and D; E stands for encryption and D stands for decryption. And the only property. That we need to satisfy is that decryption is the opposite of encryption. In other words if I encrypt a message M using a particular key. And I decrypt using the same key. I get back the original message. Last time we looked at a couple of weak cyphers like the substitution cypher and the vigonaire cypher. We showed that all of them can be easily broken so you should never ever, ever use those cyphers. Those were just for historical reference. And then we looked at our first example of a good cypher, namely the one-time pad. So let me just remind you how the one-time pad is defined. Basically the message space is the set of all bit end bit strings. The cypher text is a set of all bit end bit strings. And similarly, the key. Is the set of all N bit strings and the way we encrypt is by a simple exor to encrypt the message we just exor the message in the key that gives us the cypher text. And then to decrypt a cypher text, we just do this x over again and it's easier to show by properties of x over that in fact decryption is the opposite of encryption. And then we talked about this lemma, in fact, we proved it, that says that the one-time pad has perfect secrecy, which means that if you're just an eavesdropper and you just get to see a single cypher text, you're not going to be able to deduce any information about the encrypted plain text. Unfortunately. We also said that Shannon proved this lemma, we called it the bad news lemma, that basically says that any cypher that has perfect secrecy must have really long keys. In other words, the key length must be at least as long as the length of the message, which means that the cypher is not particularly useful. Because if two parties have a way to agree on really long keys that are as long as the message, they, in some sense, might as well use that mechanism to already transmit the message itself.\n",
    "\n",
    "## OTP\n",
    "So recall that the one time pad encrypts messages by XORing the message and a secret key, where the secret key is as long as the message. Similarly, decryption is done by similarly XORing the cipher text, and the same secret key. When the key is uniform and random, we prove that the one-time pad has this information theoretic security that Shannon called perfect secrecy. A problem was, of course, the keys are as long as the message, so the one-time pad is very difficult to use. We then talked about a way to make the one time pad practical by using a pseudo random generator that expands a short seed into a much larger message and the way a stream cypher worked, essentially using a pseudo random generator, was in the same way as the one time pad, basically, but rather than using a truly random pad, we used this pseudo random pad that's expanded to be as long as the message from the short key that's given as input to the generator. We said now the security no longer relies on perfect secrecy because stream ciphers cannot be perfectly secure. Instead security relies on properties of the pseudo random generator and we said that the pseudo random generator essentially needs to be unpredictable, but in fact it turns out that definition is a little bit hard to work with and we're going to see a better definition of security for PRGs in about two segments.\n",
    "\n",
    "## Stream ciphers\n",
    "\n",
    "Idea: replace random key by pseudorandom key. \n",
    "\n",
    "For the stream ciphers, we introduce a PRG: Pseudo-random generator.\n",
    "\n",
    "A **PRG** is a deterministic function G:{0,1}^s (seed space) -> {0,1}^n, n>>s.\n",
    "\n",
    "In stream ciphers, seed = key and define the following operations.\n",
    "E(k,m) := m XOR G(k)\n",
    "D(k,c) :=  c XOR G(k)\n",
    "\n",
    "### PRG\n",
    "\n",
    "In a perfectly secure cipher the key must be as long as the message and therefore it is not possible that the stream cipher has perfect secrecy.\n",
    "\n",
    "For a stream cipher to be secure we have redefine what it means to be secure and some other properties which are:\n",
    "\n",
    "A PRG must be unpredictable for a stream cipher to be secure. \n",
    "\n",
    "We say G:K -> {0,1}^n is predictable if there exists an efficient algorithm A and there exists an i: \n",
    "```\n",
    "1< i<n-1 such as Pr[A(G(k))|i,…,i = G(k)|i+1] >= 1/2 + epsilon. (for some non-negligible epsilon).\n",
    "```\n",
    "\n",
    "In short, a PRG is unpredictable: for all i, there is no efficient algorithm A, that can predict the i+1 bit following the prefix.\n",
    "\n",
    "**NEVER USE Weak PRGs: Linear congruential generators (glibc random).** \n",
    "\n",
    "**Negligible and non-negligible** In practise, epsilon is a scalar such as the event is not likely to happen. In theory, non-neg is defined as there exists d: epsilon(polynomial lambda) >= 1/(lambda^d) infinitely often. \n",
    "\n",
    "TLDR’: The function is negligible if it’s less than all polynomial fractions. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Attacks on OTP / stream ciphers\n",
    "\n",
    "The two time pad is insecure. \n",
    "```\n",
    "Example: \n",
    "c_1 = m_1  XOR PRG(k)\n",
    "c_2 = m_2 XOR PRG(k)\n",
    "```\n",
    "\n",
    "If an attacker gets c_1 and c_2, he can perform c_1 XOR c_2 = m_1 XOR m_2\n",
    "\n",
    "The english language (and ASCII encoding) has enough redundancy to find m_1 and m_2. \n",
    "\n",
    "Vulnerabilities found in Project Venona (1941-1946), MS-PPTP (Windows NT) and WEB where the same pad would be used every 16M frames. Even worse, most Wi-Fi cards do reset their IV back to zero on restart, causing the two time pad to appear way quicker because IC is concatenated with a long-term identity key.\n",
    "\n",
    "In disk encryption, issue of the one time pad is **malleability**. Because OTP *does not provide integrity-checking*, cipher text could be altered without the user knowing. If you know the difference between two strings, you can XOR that difference on the cipher text without knowing the key and it be changed in the cipher text without you having to know the key.\n",
    "\n",
    "And we say that the one time pad is malleable because it's very easy to compute in cipher texts, and make prescribed changes to the corresponding plain text. So to prevent all this, I'm gonna do that, actually, in two or three lectures. And we're gonna basically show how to add integrity to encryption mechanisms in general. But right now I want you to remember that the one time pad by itself has no integrity and is completely insecure against attackers that actually modify the cipher texts. \n",
    "\n",
    "## Modern broken stream ciphers\n",
    "\n",
    " **RC4** (1987) - stream cipher designed to be implemented in *software*- takes a variable size seed, expands it to a broader number of bits and then generates 1 byte (of pseudorandom) per round.  Weaknesses: 1) ex. Pr[2nd byte = 0] = 2/256 if seed = 128bits and expansion to 2048bits. (256th first bytes are biased) 2) Pr[(0,0)] is getting bigger than it should after a few gigs of data. Should not be used anymore.\n",
    "\n",
    "**CSS** is a stream-cipher used for encrypting DVDs. It’s badly broken. It was designed to be implemented on *hardware* and based on a mechanism called **LFSR** (linear feedback shift register), also used for GSM encryption (A5/1,2) and Bluetooth (E0). LFSR-derived stream ciphers are all badly broken but hard to fix because implemented in hardware.\n",
    " \n",
    "LFSR is works: \n",
    "- We have a register of n bits.\n",
    "- At every clock cycle, we shift the entries of the registry to the left, the last bit falls off and the first bit becomes the result of the XOR of all bits of the register of the previous state.\n",
    "- Seed = initial state of the register.\n",
    "\n",
    "CSS: \n",
    "- seed = 5 bytes = 40 bits (because crypto-regulations in the US only allowed exports of crypto using 40 bits keys!)\n",
    "- 2 LFSRs (17-bit and 25-bits). The first one is seeded with (1 + first 2 bytes of the key) and the second one is seeded with (1 + last 3 bytes of the key). Each of the LFSRs do produce 8 bits outputs (in 8 cycles) that are then added and mod 256 + carry of previous block. And this outputs one byte per round that is then XORed with the byte of the movie we are trying to encrypt.\n",
    "\n",
    "CSS can be broken in 2^17.\n",
    "\n",
    "## Better modern stream cipher\n",
    "\n",
    "Better PRG are coming from the **eStream** project (2008) .\n",
    "PRG: {0,1}^s x R (nonce) -> {0,1}^n\n",
    "\n",
    "A **nonce** is a non-repeating value for a given key.\n",
    "\n",
    "E(k,m,r) = m xor PRG(k,r)\n",
    "\n",
    "The pair (k,r) is never used more than once => You can reuse the key because a nonce make the key unique. \n",
    "\n",
    "## Let’s do some Salsa!\n",
    "\n",
    "**Salsa20** was designed to be easy to implement on both software and hardware. It was part of the eStream project and was submitted by DJB.\n",
    "\n",
    "Salsa20: {0,1}^{128 or 256} x {0,1}^64 -> {0,1}^n (max n=2^73)\n",
    "\n",
    "Salsa20(k,r) := H(k, (r,0) ) || H(k, (r,1) ) || … \n",
    "\n",
    "How is that function H(k, (r,i) ) defined?\n",
    "\n",
    "For the 128 version of Salsa20, we start with 64 bytes defined as in this slide. T_0…3 is defined in the Salsa20 specification. You perform 10 rounds of an invertible function h and do add all of the them word by word and you get a 64 byte output. \n",
    "\n",
    "![Salsa20](http://f.cl.ly/items/0841112C3n1v0Y3m1o2t/Screen%20Shot%202014-01-21%20at%2022.26.38.png)\n",
    "\n",
    "There are no significant attacks known on Salsa20. Very fast stream cipher in both software and hardware. In crypto++, RC4 = 126 MB/s and Salsa20=643 MB/s. \n",
    "\n",
    "## PRG Security\n",
    "\n",
    "The seed space is really small compared to the universe {0,1}^n. A pseudorandom generator outputs would look indistinguishable from a uniform distribution on {0,1}^n. \n",
    "\n",
    "One way to test if a PRG is pseudorandom we do perform statistical tests. How do we evaluate if a statistical test is good? We define the advantage of a statistical test A over the generator G: Adv[A,G] = | Pr[A(G(k))=1 ]- Pr[A(r) =1] | (between 0,1) \n",
    "\n",
    "If the advantage happen to be close to 1 it means that the generator behaved differently from the random distribution. This statistical test can distinguish the difference from random. If the advantage is close to 0, A can not distinguish the generator from random. \n",
    "\n",
    "The test A is said to break the generator if it has an advantage close to 1. \n",
    "\n",
    "If the statistical test always outputs 0, it’s advantage is 0. \n",
    "\n",
    "We define a **secure PRG** such as, for all statistical tests A, Adv[A,G] is negligible. A secure PRG is unpredictable.\n",
    "\n",
    "So, can we prove it? No we can’t. ( p != np) but we have heuristic candidates.\n",
    "—\n",
    "If PRG is predictable => PRG is insecure (can be proved easily by using the advantage definition of a secure PRG). If next-bit predictors cannot distinguish G from random then no statistical test can!\n",
    "\n",
    "## What is a secure cipher?\n",
    "\n",
    "In the context of stream ciphers remember these are only used with a onetime key, and as a result the most the attacker is ever going to see is just one cypher text encrypted using the key that we're using. And so we're gonna limit the attackers? ability to basically obtain just one cypher text.\n",
    "\n",
    "Shanon definition of security perfect secrecy where Shannon's idea was that in fact when the attacker intercepts a cipher text he should learn absolutely no information about the plain texts. He shouldn't even learn one bit about the plain text or even he shouldn't learn, he shouldn't even be able to predict a little bit about a bid of the plain text. Absolutely no information about the plain text.\n",
    "We can adapt the definition of perfect secrecy from Shannon with the concept of computational indistinguishability. \n",
    "\n",
    "For every message m_0, m1 in M: E(k, m_0) is computationally indistinguishable from E(k, m_1). \n",
    "\n",
    "A cipher is **semantically secure** if for all efficient adversary A, Adv[A, cipher] is negligible. \n",
    "A stream cipher with a secure PRG is symantically secure\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 2\n",
    "\n",
    "# Block Ciphers\n",
    "\n",
    "* A block cipher maps n bits of inputs to n bits of output. \n",
    "* So a block cipher is made up of two algorithms, **E** and **D**. These are **encryption** and **decryption** algorithms. And both of these algorithms take, as input, a key **K**. Now, the point of a block cipher is that it takes an N bit plain text as **input**, and it outputs exactly the same number of bits as **outputs**. So it maps N bits on inputs to exactly N bits of outputs.\n",
    "\n",
    "\n",
    "* **Examples :** \n",
    "- **3DES: n=64bits, k=168 bits**\n",
    "* In triple-DES the block size, namely the number of input bits, is 64. So triple-DES will map 64-bit blocks to 64-bit blocks and it does it using a key that's 168 bits long. We're gonna talk about how Triple DES is built in the next segment.\n",
    "\n",
    "- **AES: n=128bits, k = 128,192,256 bits**\n",
    "* AES has slightly different parameters. So, here the block size is 128 bits. So, AES will map a 128 bits of input to 128 bits of output. And it actually has three possible sizes of keys, and I wrote down these sizes over here. Basically the longer the key, the slower the cipher is, but presumably the more secure it is to break.\n",
    "\n",
    "\n",
    "* Block ciphers are typically built by iteration. They take in as input a key K, for example in the case of AES the key could be 128 bits long, and the first thing that happens to the key is that it gets expanded into a sequence of keys K1 to Kn called round keys. Now, the way the cipher uses these round keys is by iteratively encrypting the message again and again and again using what's called a round function. So here we have this function R that take two inputs. This function R is gonna be called a round function. It takes as input the round key, and it takes as input the current state of the message. So here we have our input message. Say, for AES, the message would be 128 bits exactly, because each block in AES is exactly 128 bits. And then the first thing that happens is we apply the first round function using the key K1 to the message. And we get some new message out, as a result. Then we take this message m1, we apply the next round function to it using a different key, using the key k2. Then we get the next round message out. And so on and so forth until all the rounds have been applied and then the final output is actually the result of the cipher. And again this would be also in the case of AES, this was 128 bits. And the resulting cipher text would also be 128 bits. \n",
    "\n",
    "**Block ciphers are considerably slower than stream ciphers. (+/- 6x slower if you compare Salsa to AES)**\n",
    "\n",
    "## Pseudo Random Function (PRF)\n",
    "\n",
    "* A PRF is defined over (K, X, Y) with F: K x X -> Y such  that there exists an efficient algorithm to evaluate F(k,x). So a pseudorandom function basically is defined over a key space, an input space, and an output space. And all it is, is basically a function that takes a key and an input as inputs and outputs some element in the output space. Okay, so it takes an element in K, an element in X, and outputs an element in Y. And the only requirement essentially, is that there's an efficient way to evaluate the function. \n",
    "\n",
    "**Note: A PRF doesn’t need to be revertible.** \n",
    "\n",
    "## Pseudo Random Permutation (PRP)\n",
    "\n",
    "* So a pseudo-random permutation is, again, defined over a key space, and then just a set X. And what it does is it takes an element in the key space, an element of X, and outputs, basically, one element in X. Now, as usual, the function E should be easy to evaluate. So there should be an algorithm to evaluate the function E. But more importantly, once we fix the key K, it's important that this function E be one-to-one. In other words, if you think of the space X as the set here, and here's the same set X again, then basically the function E, what it does, is, it's a one-to-one function, so every element in X gets mapped to exactly one element in X. \n",
    "\n",
    "* A PRP (block cipher) is defined over (K,X) with E: K x X -> X such that:\n",
    "    - Exists efficient and deterministic algorithm to evaluate E(k,x)\n",
    "    - The function E(k, ・) is one-to-one.\n",
    "    - Exists an efficient inversion algorithm D(k,y)\n",
    "\n",
    "\n",
    "* Okay, so we have two examples, as we said, of pseudorandom permutations, triple DES and AES, say for AES-128. The key space would be 128 bits and the output space would be 128 bits. For Triple DES, as we said, the block size is only 64 bits. And the key size is 168 bits, okay. So we'll use these running examples actually throughout, so whenever I say a PRP, concretely you should be thinking AES or triple DES. Now one thing that I wanted to point out is that in fact any pseudo-random permutation, namely any block cipher, you can also think of it as a PRF\n",
    "\n",
    "* **Examples:**\n",
    "    - 3DES: K x X -> X where X = {0,1}^64 , K = {0,1}^168\n",
    "    - AES: K x X -> X where K = X = {0,1}^128\n",
    "\n",
    "* Any block cipher or PRP is also a PRF : A PRP is a PRF where X = Y and is efficiently invertible.\n",
    "\n",
    "### Secure PRF\n",
    "\n",
    "```\n",
    "Let F: K x X -> Y be a PRF\n",
    "Funs[X,Y]: the set of all functions from X to Y\n",
    "S_{F} = { F(k,・) s.t. k ∈ K} ⊆ Funs[X,Y]\n",
    "```\n",
    "\n",
    "* Intuition: A PRF is secure if a random function in Fun[X,Y] is indistinguishable from a random function in S_F.\n",
    "\n",
    "### PRF gives us a PRG\n",
    "```\n",
    "Let F: K x {0,1}^n -> {0,1}^n be a secure PRF. \n",
    "Then the following G: K -> {0,1}^{nt} is a secure PRG: G(k) = F(k,0) || F(k,1) || … || F(k,t)\n",
    "```\n",
    "\n",
    "* Key property: parallelizable\n",
    "* Security from PRF property: F(k,・) indistinguishable from a random function f(・)\n",
    "\n",
    "## DES (Data Encryption Standard)\n",
    "\n",
    "* Early 1970: Horst Feistel designs Lucifer at IBM. key-len = 128 bits, block-len = 128 bits.\n",
    "    * 1973: NBS (old name of NIST) asks for block cipher proposals. IBM submits variant of Lucifer. \n",
    "    * 1976: NBS adopts DES as a federal standard. key-len = 56 bits. block-len = 64 bits.\n",
    "    * Note: This is yet another example where standard bureaus do weaken cryptography. \n",
    "    * 1997: DES broken by exhaustive search\n",
    "    * 2000: NIST adopts Rijndael as AES (Advanced Encryption Standard) to replace DES.\n",
    "\n",
    "* **Widely deployed in banking (ACH) and commerce.**\n",
    "\n",
    "## Feistel Network\n",
    "```\n",
    "Given functions f_1, …, f_d: {0,1}^n -> {0,1}^n \n",
    "Goal: build invertible function F:{0,1}^{2n} -> {0,1}^{2n}\n",
    "A Feistel Network mapping a 2n bit input to 2n bit output:\n",
    "Encryption\n",
    "L_i = R_{i-1}\n",
    "R_i =  L_i XOR f_i (R_{i-1})\n",
    "Decryption\n",
    "L_i = f_{i+1} (L_{i+1}) XOR R_{i+1}\n",
    "R_i = L_{i+1}\n",
    "```\n",
    "\n",
    "![Construct Inverse](http://cl.ly/TZkE/Screen%20Shot%202014-01-26%20at%2013.42.32.png)\n",
    "\n",
    "* Feistal networks are a general method for building invertible functions (block ciphers) from arbitrary functions. And it’s used in many block ciphers but not AES. \n",
    "\n",
    "* The Luby-Rackoff Theorem proves that if I take a secure PRF and let it go through 3 rounds of a Feistal network, the result is a secure PRP. \n",
    "```\n",
    "Formally\n",
    "f: K x {0,1}^n -> {0,1}^n a secure PRF => 3-round Feistel F: K^3 x {0,1}^{2n} -> {0,1}^{2n} is a secure PRP. \n",
    "```\n",
    "\n",
    "### DES is a 16 round Feistel network\n",
    "```\n",
    "f_1, … , f_1: {0,1}^32 -> {0,1}^32, f_i (x) = F{k_i, x} where k_i is a round key from the key expansion.\n",
    "```\n",
    "\n",
    "For decryption, the algorithm is the same but you use the round keys in reverse-order. \n",
    "```\n",
    "F(k_i, x) is taking a 32-bit value x and a 48-bit round key k_i.\n",
    "```\n",
    "\n",
    "* And now that we understand that, we can actually look at the specifics of DES. So DES is basically a sixteen round Feistel network, okay. So there are functions F1 to F16 that map 32 bits to 32 bits, and as a result, the DES itself acts on 64 bit blocks, 2x32. Now the sixteen round functions in DES are actually all derived from a single function F. Just used with different keys. So in fact, these are the different round keys. So K<u>i is, a round key. And it's</u> basically derived from the key K, derived from the 56 bit DES key K. Okay and I'll describe what this function F is in just a minute. But basically that, you see that by using sixteen different round keys, we get sixteen different round functions. And that gives us the Feistel network. So just on a high level how the DES works basically you have a 64 bit input. The first thing it does is, this initial permutation that just permutes the 64 bits around. Namely it maps bit number one to bit number six. Bit number two to bit number seventeen, and so on. This is not for security reasons, this is just specified in the standard. Then we go into the sixteen round Feistel network. That actually, you now know how it works. Basically uses the function F1 to F16, as specified before. And then, basically we have another permutation, it's called the final permutation. That's just the inverse of the initial permutation. Again, it just permutes bits around, this is not necessary for security reasons. And then we finally get, the final outputs. Okay. Now, as we said, there's a key expansion step, which I'm not gonna describe. But basically, this 56-bit DES key is expanded into these rounds keys. Where each round key, is 48 bits. Okay, so we have sixteen 48 bit round keys, and they're basically used in the sixteen rounds of DES. And then when you want to invert the cipher, all you do is you use these, round keys, these sixteen round keys, in reverse order. Okay, so now that we understand the DES structure, the only thing that's left to do is specify the function, capital F. \n",
    "\n",
    "* So let me explain how this function works. So basically, it takes, as inputs, its, 32 bit value, let's call it X. But in reality, you remember, this is R<u>0, R<u>1, R-2, R<u>3, so on and so</u></u></u> forth. These are 32 bit values. And then it takes, also, a 48 bit round key. \n",
    "\n",
    "![F function](http://cl.ly/TYeV/Screen%20Shot%202014-01-26%20at%2014.03.08.png)\n",
    "\n",
    "### S-boxes\n",
    "\n",
    "* S-boxes are just lookup tables. If S-Boxes were linear (if the S-boxes could be written as a Matrix vector product), the entire cipher would be linear and quickly broken. If S-Boxes would be random, it would result in an insecure block cipher (key recovery after 2^24 outputs). \n",
    "\n",
    "* So what are the creators of DES advising to make S boxes lookup tables? \n",
    "    - No output bit should be close to a linear function of the input bits\n",
    "    - S-boxes are 4 to 1 maps.\n",
    "\n",
    "\n",
    "### Exhaustive search on DES\n",
    "\n",
    "* **Goal:** given a few input/output pairs (m_i, c_i = E(k, m_i)), find key k. \n",
    "\n",
    "* Lemma: Suppose DES is an **ideal cipher** (2^56 random invertible functions). Then for all m,c there is at most one key k such that c = DES(k,m).\n",
    "\n",
    "* With two input-output pairs, the probability that the key is unique is very close to one for both DES and AES. Hence, two input/output pairs are enough for exhaustive key search. \n",
    "\n",
    "* RSA issued a challenge to break DES exhaustively:\n",
    "    - 1997: Internet Distributed Search = 3 months\n",
    "    - 1998: EFF machine (deep crack) = 3 days\n",
    "    - 1999: combined search = 22 hours\n",
    "    - 2006: COPACOBANA (FPGA) = 7 Days (cheap!)\n",
    "\n",
    "**DES is broken**\n",
    "\n",
    "* How do we make DES more expensive to do exhaustive search? More rounds!\n",
    "\n",
    "#### Method 1: Triple DES. \n",
    "\n",
    "* Triple DES is also 3x slower for encryption :( \n",
    "\n",
    "* The key-size of 3DES is 3*56 bits = 168 bits but does not provide 168 bits security only 118 bits. -> Meet in the middle attack\n",
    "\n",
    "* For 2DES: exhaustive search is formulated as finding (k_1,k_2) such that E(k_1, E(k_2, M)) = C. A meet-in-the-middle attack is E(k_2, m) = D(k_1,c)\n",
    "\n",
    "    * Step 1: Build table of pairs (k0…kN ; E(k0, M)…E(KN, M)\n",
    "    * Step 2: For all k ∈ {0,1}^56: test if D(k,C) is in 2nd column. \n",
    "    * Step 3: If found, then E(k^i, M) = D(k,c) => (k^i, k) = (k_2, k1) \n",
    "\n",
    "* Running time = Time = 2* 2^56  * log 2^56 < 2^63 << 2^112 \n",
    "\n",
    "* Same attack on 3DES: Time = 2^(118), space = 2^56\n",
    "\n",
    "#### Method 2: DESX\n",
    "```\n",
    "E: K x {0,1}^n —> {0,1}^n a block cipher. EX((k,1,k2,k3), m) = k_1 XOR E(k_2, m XOR k_3)\n",
    "key-length = 184 bits. Attack known in 2^120.\n",
    "```\n",
    "\n",
    "## Implementation attacks on block ciphers\n",
    "\n",
    "## Side channel attacks\n",
    "\n",
    "* Measuring noise, time, power consumption for encryption and decryption.\n",
    "\n",
    "## Fault attacks\n",
    "\n",
    "* Computing errors in the last round expose the secret key k. \n",
    "\n",
    "### Conclusion on implementation attacks\n",
    "\n",
    "* Don’t even implement these primitives yourself!\n",
    "\n",
    "## Attacks on block ciphers\n",
    "\n",
    "### Linear and differential attacks (Linear cryptanalysis)\n",
    "\n",
    "* Given many inp/out pairs, can recover key in less than exhaustive search (2^56 for DES)\n",
    "```\n",
    "Pr[m[i_1] XOR … XOR m[i_r] XOR c[j_j] XOR … XOR c[j_v] = k[l_1] XOR … XOR k[l_u] ] = 1/2 + epsilon\n",
    "```\n",
    "\n",
    "* For DES, epsilon = 1/(2^(21)) because the fifth S-Box is too close to a linear function. \n",
    "\n",
    "* How can we attack it to find key bits? \n",
    "\n",
    "* Given 1/epsilon^2 random (m, c=DES(k, m) ) pairs then \n",
    "```\n",
    "k[l_1, … , l_u] = MAJ [ m[i_1 , … , i_r] XOR c[j_j, …,j_v] ] with probability 97.7%. \n",
    "```\n",
    "\n",
    "* For DES, with 2^42 inp/out pairs, you can find k[l_i, …, l_u] in time 2^42. Roughly speaking: you can find 14 = 2 +12(from the 5th S-box) key bits this way in time 2^42.\n",
    "\n",
    "* There are 42 remaining bits in the key. Overall, the total attack time = 2^43 way better than 2^56! Better than exhaustive search.\n",
    "\n",
    "* **Lesson: A tiny bit of linearity in S_5 lead to a 2^42 time attack! NEVER DESIGN YOUR OWN BLOCK CIPHER.** \n",
    "\n",
    "### Quantum attacks\n",
    "\n",
    "* If you could build a quantum computer, a generic search problem that would be solved in O( |X| ), can be solved in O( |X|^(1/2) ) whatever the function is. \n",
    "\n",
    "* Examples:\n",
    "    - DES = 2^28\n",
    "    - AES-128 = 2^64\n",
    "    - AES-256 = 2^128 \n",
    "\n",
    "## AES\n",
    "* History \n",
    "\n",
    "    - 1997: NIST publishes request for proposal \n",
    "    - 1998: 15 submissions (5 claimed attacks)\n",
    "    - 1999: NIST chooses 5 finalists\n",
    "    - 2000: NIST chooses Rijndael as AES (designed in Belgium)\n",
    "\n",
    "* Key sizes = 128, 192, 256 bits. Larger keys: slower but thought to be more secure.\n",
    "    * Block size = 128 bits\n",
    "\n",
    "### Design\n",
    "\n",
    "* AES is a substitution-permutation network. In a Feistal network, half of the bits are not changed in every round. In a subs-perm network, all bits are changed on every round. \n",
    "\n",
    "    * AES-128 schematic \n",
    "\n",
    "![AES-128](http://cl.ly/Tc1N/Screen%20Shot%202014-01-28%20at%2014.36.28.png)\n",
    "\n",
    "* AES operates on 128 bits, a 4x4 matrix, each cell containing a byte. Then we XOR with the first round key, apply the round function, x10 and then we get the output. The keys are coming from the 16 bytes AES key using key expansion.\n",
    "\n",
    "* So for example, AES 128 is the fastest of these ciphers and AES 256 is the slowest. Now AES is built as what?s called a substitution permutation network. It's not a Faistl network. Remember that in a Faistl network, half the bit were unchanged from round to round. In a substitution permutation network all the bits are changed in every round. And the network works as follows, so here we have the first round of the substitution permutation network, where the first thing we do is we X or the current state with the round key. In this case the first round key. Then we go thru a substitution layer, where blocks of Date are replaced with other blocks based on what the substitution table says. And then we go through a permutation layer where bits are permuted and shuffled around. And then we do this again. We XR with an X round key, we go thru a substitution phase, and we're permute to dance around. And so on, and so on, and so forth Until we reach the final round where we x or with the very last around key, and then out comes the output. Now, and important point about this design. Is that, in fact, because of how it's built, every step in this network needs to be reversible, so that the whole thing is reversible. And so the way we would, decrypt, essentially, is we would take the output and simply apply each step of the network in reverse order. \n",
    " \n",
    "![AES-128-RoundFunctions](http://cl.ly/TbLk/Screen%20Shot%202014-01-28%20at%2014.36.35.png)\n",
    "\n",
    "* Overview of the round function: \n",
    "    - Byte substitution: one byte S-Box (256 byte table). We take the current cell as an index into the lookup table, and the value is the output.\n",
    "    - Shift row step: We shift the second row from 1 position, third row by 2 positions and last row by 3 positions.\n",
    "    - Mix column: We apply a linear transformation to each of the communes independently. \n",
    "\n",
    "### How to use AES\n",
    "\n",
    "* If you want to send an implementation over a network. Don’t send precomputed table but algorithm to compute it. And then compute them upon receival. \n",
    "\n",
    "* AES is implemented in hardware. aesenc, aesenclast: one round of aes. aeskeygenassist, perform key expansion. 14 times faster than software. \n",
    "\n",
    "### Attacks on AES\n",
    "\n",
    "* Best key recovery attack: four times better than exhaustive search. 128key => 126 key.\n",
    "\n",
    "* Related key attack on AES-256: If related keys => 2^99 security! *Importance to choose keys at random*.\n",
    "\n",
    "## Building block ciphers from PRG\n",
    "\n",
    "* Can we build a PRF from a PRG? \n",
    "\n",
    "* Let’s start with a PRG G such that \n",
    "\n",
    "```\n",
    "G:K -> K^2 be a secure PRG. \n",
    "\n",
    "Define 1-bit PRF F:Kx{0,1} -> K as F(k, x in {0,1}) = G(k)[x]\n",
    "```\n",
    "\n",
    "* If G is a secure PRG, then F is a secure PRF on {0,1}^n => Not used in expanded mode due to performance reasons. \n",
    "\n",
    "* Thanks to the Luby-Rackoff theorem, we know that we can thus make a secure PRP with a 3-round Feistal network.\n",
    "\n",
    "# Week2 Review Questions and Programming Project\n",
    "\n",
    "* A block cipher maps, N bits of inputs to N bits of outputs. And we saw two examples of block ciphers, triple DES and AES.\n",
    "\n",
    "* **PRF -> function, X -> Y, doesn’t have to be the same.** \n",
    "\n",
    "* A pseudo-random function, a PRF, basically is a function that takes two inputs. It takes a key and an element in some set X. And in outputs an element in some set Y and for now the only requirement is that there's an efficient algorithm to evaluate this function. \n",
    "\n",
    "* **PRP -> One to one revertible function. Domain X=Y. Key concept to build a block cipher.**\n",
    "\n",
    "* And then similarly, there's a related concept called a pseudo-random permutation, which is similar to a PRF. In fact, there's also an efficient algorithm to evaluate, the pseudo-random permutation. However, there's an additional requirement, that there's also an algorithm D that will invert this function E. So a PRP, is basically a PRF, but where the function is required to be one to one for all keys. \n",
    "\n",
    "* Any secure PRP is also a secure PRF if |X| is sufficiently large.\n",
    "\n",
    "```\n",
    "Lemma: Let E be a PRP over (K,X) then for any q-query adversary A: |Adv_{PRF} [A,E] - Adv_{PRF} [A,E] | < q^2 / 2|X|\n",
    "When X is large, the ratio will be negligible.\n",
    "```\n",
    "\n",
    "* **From now on, we consider AES or 3DES as secure PRPs.**\n",
    "\n",
    "* As a final note, I just want to mention that, really, from now on, you can kinda forget about the inner workings of AES and triple DES. We're simply gonna assume that both are secure PRPs, and then we're gonna see how to use them. But whenever I say PRP, or PRF, you should be thinking in your mind, basically, AES or triple DES. \n",
    "\n",
    "## Security for one-time key\n",
    "\n",
    "* **Let’s start with a threat model (one-time keys) defined as follows:**\n",
    "- Adversary’s power: Adv sees only one cipher text\n",
    "- Adversary’s goal: Learn info about PT from CT (semantic security)\n",
    "* So in this segment we're just gonna use the block cipher to encrypt using keys that are used one time. In other words, all the adversary gets to see is one ciphertext, and its goal is to break semantic security of that ciphertext. \n",
    "\n",
    "\n",
    "* **So this mode of operation is called an electronic code book.**\n",
    "* And it works as follows: it's the first thing that comes to mind when you want to use a block cipher for encryption. What we do is we take our message, we break it into blocks, each block as big as the block's cipher block. So in the case of AES, we would be breaking our message into sixteen byte blocks. And then we encrypt each block separately. So this mode is often called electronic codebook. And, unfortunately, it's terribly insecure because you realize if two blocks are equal, for example here, these two blocks happen to be equal, then necessarily the resulting ciphertext is also going to be equal. So an attacker who looks at the ciphertext, even though he might not know what's actually written in these blocks, we'll know that these two blocks are equal.\n",
    "\n",
    "* **Reminder:** semantic security for a one-time key. The attacker, if given c_0 and c_1 and m_0 and m_1 can’t know which one is the result of what message.\n",
    "```\n",
    "Adv_{SS} [A, OTP] = | Pr[ EXP(0)=1 ] - Pr[ EXP(1) = 1 ] |\n",
    "```\n",
    "\n",
    "# Security for many-time key, nonce, randomized encryption\n",
    "\n",
    "* Why? Many applications: Filesystems or IPSec, encrypts a lot of traffic with the same key. When we use a key more than once, the adversary sees many cipher texts with the same key. \n",
    "\n",
    "* Adversary power: **chosen-plaintext attack**, the attacker can obtain the encryption of arbitrary messages of his choice (How does it work IRL? You can email someone, email will be stored encrypted on disk and boom you have m and c).\n",
    "\n",
    "* Adversary goal: **Break semantic security**\n",
    "\n",
    "* Semantic-security for many-time key is defined exactly as semantic security for a one-time key but he can repeat any of the messages in the challenge that the attacker can choose. ==> Chosen Plaintext attack.\n",
    "    * All the deterministic encryption schemes we’ve seen before are broken under CPA. \n",
    "* So how do we fix this?\n",
    "\n",
    "1) **Randomized encryption**: encrypting same message twice gives different cipher text. Ciphertext must be longer than plaintext. size(CT) = size (PT) + “#random bits”\n",
    "\n",
    "2) **Nonce-based encryption**. We define a **nonce** as a value that changes from message to message. The pair (k, n) should NEVER be used more than once. The nonce can conveniently be a counter (if in-order and reliable transmission channel, no need to transmit nonce). If same key used by multiple machines, the nonce space needs to be very big and picked at random (easier to implement a “stateless” protocol)\n",
    "\n",
    "* The other approach to building chosen plain text secure encryption schemes is what's called a nonce based encryption. Now, in a non-spaced encryption system, the encryption algorithm actually takes three inputs rather than two. As usual it takes the key and the message. But it also takes an additional input called a nonce. And similarly, the decryption algorithm also takes the nonce as input, and then produces the resulting decrypted plain text. And what is this nonce value n. This nonce is a public value. It does not need to be hidden from the adversary but the only requirement is that the pair (k,n) is only used to encrypt a single message. In other words, this pair (k,n) must change from message to message. And there are two ways to change it. One way to change it is by choosing a new random key for every message. And the other way is to keep using the same key all the time but then we must choose a new nonce for every message. And, and as I said, I wanna emphasize again, **this nonce need not be secret**, and it **need not be random**. The only **requirement is the nonce is unique**. And in fact, we're gonna use this term throughout the course. \n",
    "\n",
    "* A nonce for us, means a unique value that doesn't repeat. It does not have to be random. So let's look at some examples of choosing an nonce, well the simplest option is simply to make the nonce of the accounter so for example the networking protocol you can imagine the nonce being a packet counter that's incremented every time a packet is sent by a sender or received by the receiver this means that the encrypter has to keep state from message to message mainly that he has to keep this counter around and increment it after every message is transmitted. Interestingly, if the decrypter actually has the same state then there is no need to include the nuance in the cipher text since the nuance is implicit.\n",
    "\n",
    "* **Https Example of Using a nonce**\n",
    "\n",
    "* Let's look at an example. The https protocol is run over a reliable transport mechanism which means that packets sent by the sender are assumed to be received in order at a recipient. So if the sender sends packet #5 and then packet #6, the recipient will receive packet #5 and then packet #6 in that order. This means that if the sender maintains a packet counter, the recipient can also maintain a packet counter and two counters basically increment in sync. In this case there is no reason to include the nonce in the packets because the nonce is implicit between the two sides.\n",
    "\n",
    "* **IPSec**\n",
    "\n",
    "* However, in other protocols, for example, in IPsec, IPsec has a protocol designed to encrypt the IP layer. The IP layer does not guarantee in order delivery. And so the sender might send packet #5 and then packet #6, but those will be received in reverse order at the recipient. In this case it's still fine to use a packet counter as a nonce but now the nonce has to be included in the packet so that the recipient knows which nonce to use to decrypt the received packet.\n",
    "\n",
    "* So now we understand what it means for a symmetric system to be secure when the keys used to encrypt multiple messages the requirement is that it be secure under a chosen plan of attack. And we said that basically, the only way to be secure under a chosen plain text attack is either to use randomized encryption, or to use, use nonce spaced encryption where the nonce never repeats.\n",
    "\n",
    "## Modes of operation\n",
    "\n",
    "Goal: Build a secure encryption from a secure PRP\n",
    "\n",
    "### ECB (Electronic Code Book) - One time key\n",
    "\n",
    "* ECB is badly broken. It works by breaking down the message into n blocks of size of the block cipher and then encrypt each of the parts individually. Issue, the attacker learns when a two segments have the same value. (if m_1 = m_2 -> c_1 = c_2)\n",
    "\n",
    "* ECB is not semantically secure.\n",
    "![ECB’s advantage is 1!](http://cl.ly/Tdm9/Screen%20Shot%202014-01-30%20at%2011.28.png)\n",
    "\n",
    "### Deterministic counter mode from a PRF F (eg. AES) - One time key\n",
    "```\n",
    "E_{DETCTR} (k,m) = We build a stream cipher from a PRF.\n",
    "```\n",
    "\n",
    "![Deterministic Counter Mode](http://cl.ly/Te5t/Screen%20Shot%202014-01-30%20at%2011.37.39.png)\n",
    "\n",
    "## CBC (Cipher Block Chaining with a random IV) - Many time key (CPA security)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## IV-based encryption\n",
    "\n",
    "* We are going to look at a mode called cipher block chaining with a random IV. CBC stands for cipher block chaning. So suppose we have a block cipher, so EB is a block cipher. So now let's define CBC to be the following encryption scheme. So the encryption algorithm when it's asked to encrypt a message m, the first thing it's going to do is it's going to choose a random IV that's exactly one block of the block cipher. So IV is one cypher block. So in the case of AES the IV would be 16 bytes. And then we're gonna run through the algorithm here, the IV basically that we chose is gonna be XORed to the first plain text block. And then the result is gonna be encrypted using the block cipher and output of the first block of the ciphertext. And now comes the chaining part where we actually use the first block of the ciphertext to kind of mask the second block of the plaintext. So we XOR the two together and the encryption of that becomes the second ciphertext block. And so on, and so on, and so forth. So this is cIpher block chaining, you can see that each cIpher block is chained and XORed into the next plaintext block, and the final ciphertext is going to be essentially the IV, the initial IV that we chose along with all the ciphertext blocks. I should say that IV stands for Initialization Vector.\n",
    "\n",
    "* When we start encrypting the first block, we pick a random IV (initialization vector of length one bloc).  We XOR the first message with it before encrypting. \n",
    "* IV is publicly known and prepended to the cipher text. \n",
    "* Chaining is done by for the next block XORing the cipher text of the first block with the new message and then encrypting. \n",
    "\n",
    "* What security does it provide? It does provide semantic security:\n",
    "```\n",
    "\n",
    "Adv_CPA [A , E_{CBC} ] =< 2 * Adv_PRP [B, E] + (2 q^2 L^2 / |X| = error term, needs to be negligible) \n",
    "```\n",
    "\n",
    "**CBC is secure as long as q^2L^2 << |X| where L is the length of the messages and q is the number of times we used q to encrypt messages.**\n",
    "\n",
    "* Applied to AES, this means that after 2^48 blocks, we need to replace the key. \n",
    "* This means that after we use a particular key to encrypt 2 to the 48 AES blocks we have to change the key. Okay, so essentially CBC stops being secure after the key is used to encrypt 2 to the 48 different AES blocks. So its kinda nice that the security theorem tells you exactly how long the key can be used and then how frequently, essentially, you have to replace the key\n",
    "\n",
    "* Applied to DES\n",
    "\n",
    "* Now interestingly if you apply the same analogy to the 3DES it actually has a much shorter block, maybe only 64 bits, you see the key has to be changed much more frequently, maybe after every 65 thousand DES blocks, essentially you need to generate a new key. So this is one of the reasons why AES has a larger block size so that in fact modes like CBC would be more secure and one can use the keys for a longer period of time, before having to replace it. What this means is having to replace two to the sixteen blocks, each block of course is 8 bytes, so after you encrypt about half a megabyte of data you would have to change the DES key which is actually quite low. And you notice with AES you can encrypt quite a bit more data before you have to change the key.\n",
    "\n",
    "* Cipher is not CPA secure if the IV is predictable when you use CBC encryption it is absolutely crucial that the IV be random\n",
    "* *So I want to warn you about a very common mistake that people have made when using CBC with a random IV. That is that the minute that the attacker can predict the IV that you're going to be using for encrypting a particular message decipher this Ecbc is no longer CPA secure. So when using CBC with a random IV like we've just shown It's crucial that the IV is not predictable.* \n",
    "\n",
    "![IV-based encryption](http://cl.ly/ThMj/Screen%20Shot%202014-02-01%20at%2021.47.48.png)\n",
    "\n",
    "## Nonce-based encryption\n",
    "\n",
    "* Cipher-block chaining with unique nonce. (no need to include in first cipher text) If nonce is not random, it needs to be xored with first block.\n",
    "\n",
    "![Nonce-based CBC](http://cl.ly/Tgje/Screen%20Shot%202014-02-01%20at%2021.47.34.png)\n",
    "\n",
    "* Okay, so now I going to show you the nonce based version of CBC encryption So in this mode the IV is replaced by non random but unique nonce for example the numbers 1,2,3,4,5, could all be used as a nonce, and now, the appeal of this mode is that if the recipient actually knows what the nonce is supposed to be then there's no reason to include the nonce in the ciphertext, in which case, the ciphertext is exactly the same length as the plaintext, unlike CBC with the random IV, where we had to expand the ciphertext to include the IV, here, if the nonce is already known to the recipient, there's no reason to include it in the ciphertext, and the ciphertext is exactly the same length as the plaintext. So it's perfectly fine to use a non-random but unique nonce. However, it's absolutely crucial to know that, if you do this, there's one more step that you have to do before you use the nonce in the CBC chain. In particular, in this mode now we're going to be using two independent keys, k and k1. The key k is, as before, going to be used to encrypt the individual message blocks, However, this key k1 is going to be used to encrypt the non-random but unique nonce, so that the output is going to be a random IV, which is then used in the CBC chain. So this extra step here, encrypting the nonce with the key k1, is absolutely crucial. Without it, CBC mode encryption would not be secure. However it if is going to be a counter you need to do one more step. Before actually encryption CBC and in particular you have to actually encrypt the notes to obtain the IV that will actually be used for encryption. The notes on CBC is similar to a random IV, the difference is that the notes is first encrypted and the results is that the IV is used in the CBC encryption Now the beauty of this mode is that the Nance doesn't necessarily have to be included in the cipher text. It only needs to be in there if its unknowns are the decrypter but it if the decrypter happens to already know the value of the counter by some other means then in fact the cipher text is only as big as the plain text. There's no extra value transmitted in the cipher text. And again, I warn that when you're using non spaced encryption, it's absolutely crucial that the key common Nance spare is only used for one message so for every message, either the Nance has changed or the key has changed. Okay, so here emphasize the fact that you need to do this extra encryption step before actual using the Nance. This is very common mistake that actually forgotten in practice and for example in TLS, this was not done and as a result there was a significant attack against CBC encryption in TLS.\n",
    "\n",
    "\n",
    "#### Padding \n",
    "\n",
    "* In TLS, you pad the n remaining bytes with the number n. If no pad is needed, add a dummy block. One last technicality about CBC is what to do when the message is not a multiple of the block cipher block length? That is what do we do if the last message block is shorter than the block length of AES, for example? So the last message block is less than sixteen bytes. And the answer is if we add a pad to the last block so it becomes as long as sixteen bytes, as long as the AES block size. And this pad, of course, if going to be removed during encryption. So here is a typical path, this is the path that is used in TLS. Basically a pad with N bytes then essentially what you do is you write the number N, N times. So for example if you pad with five bytes, you pad with the string 555555. So five bytes where each byte is the value five. And the key thing about this pad is basically when the decrypter receives the message, what he does is he looks at the last byte of the last block. So suppose that value is five, then he simply removes the last five bytes of the message. Now the question is what do we do if in fact the message is a multiple of sixteen bytes so in fact no pad is needed? If we don't pad at all, well that's a problem because the decrypter is going to look at the very last byte of the last block which is not part of the actual message and he's going to remove that many bytes from the plain text. So that actually would be a problem. So the solution is, if in fact there is no pad that's needed, nevertheless we still have to add a dummy block. And since we add the dummy block this would be a block that's basically contains sixteen bytes each one containing the number sixteen. Okay, so we add essentially sixteen dummy blocks. The decrypter, that when he's decrypting, he looks at the last byte of the last block, he sees that the value is sixteen, therefore he removes the entire block. And whatever's left is the actual plain text. S\n",
    " \n",
    "### Randomised Counter-mode (superior to CBC) \n",
    "\n",
    "* Unlike CBC, randomised counter-mode doesn’t need a secure block cipher (PRP) but works with a secure PRF because we’re never going to invert the function F. How does it work? We pick a random IV, then we XOR the messages blocks with F(k,IV + message block number)\n",
    "* Nonce based counter mode: IV = [ 64-bit nonce | 64-bit counter (starts at 0 for every message)]\n",
    "* Note that we can encrypt a maximum of 2^64 blocks per nonce because otherwise the counter overflows and the pad would be used a second time. We can use counter-mode for more blocks than CBC because  the adversary’s advantage is 2q^2L / |X| < CBC’s advantage. \n",
    "* For AES, we can encrypt 2^64 AES blocks  with the same key with semantic secrecy. \n",
    "* Advantage: It’s parallelizable! Fast encryption! And is so much better than CBC.\n",
    "\n",
    "* Unlike CBC. Randomized counter mode uses a secure PRF. It doesn't need a block cypher. It's enough for counter mode to just use a PRF because we're never going to be inverting this function F. So we're going to let F be the secure PRF and it acts on N byte blocks. Again if we use AES, N will be 128. And the way the encryption algorithm works in counter mode is it starts off by choosing a random IV, that's 128 bytes random IV in the case of AES, and the essentially we start counting. From this random IV, so you notice the first encryption is of IV then IV+1 up to IV+L. So we generate this random pad. We XOR the result with the message, and that gives us the cipher text. And, as usual, you notice that the IV here is included along with the cipher text. So that, in fact, the cipher text is a little longer than the original plain text. And the point, of course, is that, encryption algorithm chooses a new IV for every message. And so even if I encrypt the same message twice, I'm gonna get different resulting cipher texts. One thing to notice that this mode is completely paralyzable, unlike CBC. CBC was sequential. In other words, you couldn't encrypt block #5 until you've encrypted blocks ##1 to 4, so hardware companies who might have multiple AES engines working in parallel cannot actually use those AES engines when using CBC because CBCs inherently sequential. So even though you might have two or three of four AES engines, you could only use one of them when doing CBC encryption. With counter mode, everything is completely paralyzable. If you have three AES engines encryption basically will work three times as fast. So that's the beauty of counter mode.\n",
    "\n",
    "![CBC vs Counter](http://cl.ly/TgXt/Screen%20Shot%202014-02-01%20at%2022.38.13.png)\n",
    "\n",
    "\n",
    "### Summary\n",
    "\n",
    "* I wanted to just quickly summarize and remind you that we're going to be using these PRP and PRF abstractions of block ciphers. This is actually the correct way of thinking of block ciphers and so we'll always think of them as either pseudorandom permutations or pseudorandom functions. And then I wanted to remind you again that, so far, we saw two notions of security. Both only provide security against eavesdropping. They don't provide security against tampering with the cipher text. One was used when the key is only used to encrypt a single message. The other one was used when the key was used to encrypt multiple messages. And as we said, because neither one is designed to defend against tampering, neither one provides data integrity. And we're going to see this as a real problem. And as a result, in fact, I'm going to say in the next segment that these modes actually should never, ever be used. You should only be using these modes in addition to an integrity mechanism, which is our next topic. Okay, so, so far we've seen basically for using a, the key once, you can use stream ciphers or you can use deterministic counter mode. If you're gonna use the key many times you could use randomize CBC or randomize counter mode and we're gonna talk about how to provide integrity and confidentiality.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\n",
    "# Week 3\n",
    "\n",
    "# Message Integrity \n",
    "\n",
    "## Message Authentication Codes (MAC)\n",
    "\n",
    "* A MAC is defined as (Signing ,Verification )algorithm and defined over (K, M, T) is a pair of algorithms: \n",
    "    * S(Key + Message) = Tag \n",
    "    * V(Key + Message + Tag) = Yes or No\n",
    "\n",
    "    - S(k,m), the signing algorithm, outputs t (tag) in T \n",
    "    - V(k,m,t), the verification algorithm, outputs yes or no\n",
    "\n",
    "* So as I said, our goal here is to provide integrity without any confidentiality. There are actually in fact many cases in the real world where this comes up. For example, you can think of operating system files on your disk. Say if you're using Windows, all the Windows operating system files on disk are not confidential, they're public and known to the world, but it is quite important to make sure that they're not modified by a virus or some malware. That's an example where you want to provide integrity but you don't care about confidentiality. Another example is banner ads on web pages. The provider of the ads doesn't care at all if someone copies them and shows them to other people. So there's no confidentiality issue at all. But they do care about modifying those ads. So, for example, they do wanna prevent people from changing the ads into different types of ads. So that's another example where integrity matters but confidentiality is not important at all. So how do we provide message integrity? The basic mechanism is what's called a MAC, a message authentication code, MAC. And the way we do it is as follows. So here we have our friends, Alice and Bob. They have a shared key, K, which is not known to the attacker, but known to both of them. And there's a public message M that Alice wants to send to Bob, such that an attacker along the way cannot modify this message on its way to Bob. The way Alice does it, is by using what's called a MAC signing algorithm, we'll denote it by S, where the MAC signing algorithm takes as input the key and the message, and produces a very short tag. The tag could be like 90 bits or 100 bits, or so on. Even though the message is gigabytes long, the tag is actually very, very short. Then, she appends the tag to the message and sends the combination of the two to Bob. Bob receives the message and the tag, and then he runs what's called a MAC verification algorithm on this tag. So the MAC verification algorithm takes as input to the key, the message, and the tag and it says basically yes or no, depending on whether the message is valid or whether it's been tampered with. \n",
    "\n",
    "\n",
    "* Consistency requirement: for every message and for every key: V(k, m, S(k,m)) = yes\n",
    "\n",
    "\n",
    "* Integrity requires a shared key between Alice and Bob. Algorithms like CRC do detect random errors but not malicious errors! \n",
    "\n",
    "## Secure MACs \n",
    "* Given a secure PRF(AES), then that secure PRF can actually be used to construct a secure MAC, simply by defining the signature on the message m as the value of the function at the point m. The only caveat was that the output of the PRF F had to be large. For example, it could be 80 bits or 128 bits, and that would generate a secure MAC Now we also said that because AES is a secure PRF, essentially AES already gives us a secure MAC, except that it can only process sixteen byte messages.\n",
    "\n",
    "* The attacker’s power : chose message attack:\n",
    "- for m_1 … m_q attacker is given t_i <- S(k,m_i)\n",
    "\n",
    "* The attacker’s goal: Existential forgery\n",
    "- produce some new valid message/tag pair (m,t): (m,t) different than any pair that is given to him.\n",
    "\n",
    "* **What does this mean?** \n",
    "- The attacker cannot produce a valid tag for a new message.\n",
    "- Given (m,t) attacker cannot even produce (m,t’) for t != t’\n",
    "\n",
    "\n",
    "* **Definition:** I=(S,V) is a secure MAC if for all “efficient” A: Adv_{MAC} [A, I] = Pr[Chal. outputs 1] is negligible.\n",
    "\n",
    "\n",
    "\n",
    "* A secure PRF => Secure MAC if the output space of the PRF is big enough. In practice, 80-bits is good security for a PRF. \n",
    "\n",
    "* We can use AES for 16-byte messages but how can we convert a MAC for small inputs and scale them for bigger inputs. The output of a n bit PRF can be truncated. \n",
    "\n",
    "# (encrypted) CBC-MAC\n",
    "\n",
    "Let F:K x X -> X be a PRP, define a new PRF F_ECBC:K^2 x X^{=< L} -> X\n",
    "\n",
    "![CBC-MAC construction](http://cl.ly/The8/Screen%20Shot%202014-02-03%20at%2015.36.37.png)\n",
    "\n",
    "* See how ECBC works. Well, we start by taking our message and breaking it into blocks, each block is as long as a block of the underlying function f, and then essentially we run through the CBC chain except that we don't output intermediate values. So you notice we basically encrypt the first block and then feed the results into the XOR with the second block and then feed that into f again, and we do that again and again and again and finally we get a value out here. Which is called the CBC outputs of this long chain. And then, I would like to point your attention to the fact that we do one more encryption step. And this step is actually done using an independent key, K1. That's different and chosen independently of the key K, and finally the output gives us the tag. So in this case the tag would be N bits long, but we also mentioned in the previous segment that it's fine to truncate the tag to less than N bits long as long as one over two to the end is negligible. So now you can see that FECBC takes a pair of keys as inputs, it can process variable length messages and it produces an output in the set X. So you might be wondering what this last encryption step is for. And I'll tell you that the function that's defined without this last encryption step is called the raw CBC function. In other words, if we simply stop processing over here, and we take that as the output, that's called raw CBC. And as we'll see in a minute, raw CBC is actually not a secure MAC\n",
    "\n",
    "## NMAC\n",
    "```\n",
    "Let F:K x X -> K be a PRF, define a new PRF F_NMAC : K^2 x X^{=<L} -> K\n",
    "```\n",
    "\n",
    "![NMAC Construction](http://cl.ly/TiX2/Screen%20Shot%202014-02-03%20at%2015.44.55.png)\n",
    "\n",
    "* And the way NMAC works is kind of, starts as before. We take our message, and we break it into blocks. Each block is, again, as big as the block length of the underlying PRF. And now we take our key and we feed our key as the key input into the function F. And the message block is given as the data input into the function F. What comes out is the key for the next block of NMAC. So now we have a new key for the next evaluation of the PRF. And the data for the next evaluation is the next message block and so on and so forth until we reach the final output. The final output is gonna be an element in K. Okay? And just as before, in fact, if we stop here. The function that we obtain is called a cascade function. And we're gonna look at cascade in more detail in just a minute. So cascade will output an element in K. However, that, as we'll see again, is not a secure MAC. To get a secure MAC, what we do is we need to map this element T, which is in K, into the set X. And so, typically, as we'll see, NMAC is used with, PRFs, where the block length, X, is much bigger than the key length. And so what we do is we simply append fixed pad. fpad is called a fixed pad that gets appended to this tag T. And then this becomes, this input here, this block here becomes an element of X. We feed this into the function, and again, notice here that there's an independent key that's being used for the last encryption step. And then finally, the last tag is an element of K which we output as the output of NMAC. So remember without the last encryption step, the function is called a cascade. With the last step as we'll see which is necessary for security, we actually get a PRF which outputs elements in K, and can process variable length messages that are up to L blocks long. Alright so that is the NMAC construction. So now we have two MACs. That we can use to build a large PRF, from AES, basically.\n",
    "\n",
    "![CBC-MAC vs NMAC](http://cl.ly/Tiod/Screen%20Shot%202014-02-03%20at%2015.36.37.png)\n",
    "\n",
    "\n",
    "# MAC padding\n",
    "\n",
    "* Errors in padding can have disastrous consequences, just imagine if someone can forge a banking transaction with an additional 0! \n",
    "\n",
    "* So, how do we pad?  Padding must be reversible (1 to 1) to make sure it’s unique. We pad with “100…0”. Add a new dummy block if the message size is already a multiple of the block size.\n",
    "\n",
    "## CMAC\n",
    "\n",
    "* Variant of CBC-MAC where no additional encryption step is necessary and no need to add a dummy block. \n",
    "\n",
    "```\n",
    "CMAC uses key = (k, k_1, k_2) where k_1 and k_2 are derived from K. \n",
    "```\n",
    "![CMAC construction](http://cl.ly/TiW6/Screen%20Shot%202014-02-03%20at%2017.07.21.png)\n",
    "\n",
    "## PMAC - Parallel MAC\n",
    "\n",
    "* All the PRFs seen so far for MACs are sequential. PMAC is parallel and incremental (if one block changes, no need to recompute everything). \n",
    "\n",
    "![PMAC Construction](http://cl.ly/Thwf/Screen%20Shot%202014-02-03%20at%2017.23.06.png)\n",
    "\n",
    "## One-time MAC\n",
    "\n",
    "![One Time MAC example](http://cl.ly/Til8/Screen%20Shot%202014-02-03%20at%2017.51.37.png)\n",
    "\n",
    "## Many-time MAC\n",
    "\n",
    "![Many Time MAC](http://cl.ly/TiMx/Screen%20Shot%202014-02-03%20at%2017.53.44.png)\n",
    "\n",
    "# Collision Resistance\n",
    "\n",
    "* A quick recap of where we are. In the last module we talked about message integrity where we said that the MAC system is secure if it's existentially unforgeable under a chosen message attack. This means that even an attacker who is given the tag on arbitrary messages of his choice cannot construct a tag for some new message. And then we showed that in fact any secure PRF immediately gives us a secure MAC. And so then we turned around and said well can we build secure PRFs that take large messages as inputs? And so we looked at four constructions. The first construction was based on CBC, we call it when we looked at two variants of it, one called encrypted CBC and one called CMAC. And we said that these are commonly used with AES. In fact, in the 802.11i standard, a CBC-MAC is used for message integrity. In particular, with the AES algorithm. We looked at another mode called NMAC, which also converts a PRF for short inputs into a PRF that's capable of taking very large messages as inputs. And these two were both sequential MAC-s. We then looked at the parallelizable MAC called PMAC which again was able to convert a PRF for small inputs into a PRF for very large inputs. But it did so in a parallel fashion so a multiprocessor system would be more efficient with PMAC than, say, with CBC-MAC. All three of these built a MAC for large messages by constructing a PRF for large messages. And then we looked at the Carter-Wegman MAC which is actually not a PRF. It's a randomized MAC so a single message could actually have many, many different valid tags and therefore a Carter-Wegman MAC is actually not a PRF. And if you remember, the Carter-Wegman MAC was built by first of all, taking the bulk message and hashing it down to a small tag using a fast one-time MAC and then encrypting that tag using a PRF. The benefit of the Carter-Wegman MAC was that, as we said, the hashing of the bulk message is done using a fast one time MAC. \n",
    "\n",
    "```\n",
    "Let H:M -> T be a hash function (|M| >> |T|)\n",
    "\n",
    "A **collision** for H is a pair m_0, m_1 in M such that: H(m_0) = H(m_1) and m0 != m1\n",
    "```\n",
    "\n",
    "* A function H is **collision resistant** if for all efficient algorithms A: Adv_CR [A,H] = PR[A outputs collision for H] is negligible. \n",
    "\n",
    "* If we have a collision-resistant function, we can build MACs for bigger messages from secure MACs that work on smaller messages.\n",
    "\n",
    "* This kind of scheme is very popular. In fact, Linux distributions often use public space where they advertise hashes of their software packages. And anyone can make sure that they downloaded the right software package before installing it on their computer. So this is, in fact, something that's used quite extensively in the real world. \n",
    "\n",
    "## Protecting file integrity\n",
    "\n",
    "* If we have a public read-only space and no key, we can use a collision resistant hash function to verify integrity of a package.\n",
    "\n",
    "## Birthday attack\n",
    "\n",
    "* Using the birthday paradox, we can predict collisions with probability: when n = 1.2 * B^{1/2} then Pr[collision] => 1/2 with n, number of items in attack set and B, number of items in universe.\n",
    "\n",
    "### Using Hash-functions\n",
    "\n",
    "* Use SHA-512 is recommended. \n",
    "\n",
    "### The Merkle-Damgard Paradigm\n",
    "\n",
    "![Merkle Damgard](http://cl.ly/Tiap/Screen%20Shot%202014-02-04%20at%2001.27.14.png)\n",
    "\n",
    "* Security guaranteed by theorem that claims that if h is collision resistant then so is H\n",
    "\n",
    "### Compression functions\n",
    "\n",
    "#### Davies-Meyer compression function based on block ciphers\n",
    "\n",
    "* The Davies-Meyer compression function: \n",
    "```\n",
    "h(H,m) = E(m, H) XOR H\n",
    "```\n",
    "\n",
    "* Theorem: Suppose E is an ideal block cipher. Finding collisions h(H,m)=h(H’,m’) takes O(2^(n/2)) - same as birthday attack, best possible, evaluations of (E,D).\n",
    "\n",
    "### SHA-256\n",
    "\n",
    "* SHA-256 is a Merkle-Damgard function that uses the Davies-Meyer compression function and where the block cipher used is SHACAL-2 (512-bit keys) and block size of 256 bits. \n",
    "* So let me remind you what the Merkle-Damgard construction is. Basically we have a small compression function h from which we build a large hash function, which is collision resistant assuming the compression function is collision resistant\n",
    "\n",
    "### HMAC - MAC from SHA256\n",
    "```\n",
    "HMAC: S(k,m) = H( k $\\bigoplus$ opad, H( k $\\bigoplus$ ipad || m))\n",
    "```\n",
    "\n",
    "* First we take our key k and we concatenate what's we call an internal pad to it, an ipad to it. This makes it into one block of the Merkle-Damguard construction, so for example this would be 512 bits in the case of SHA256. We prepend this to the message M and then we hash. Now this by itself we just said is completely insecure, however what HMAC does in addition, it takes the output, which is 256 bits, it prepends to that the key again XOR with, what's called the outer pad, the opad. This also becomes 512 bits. It's one block. And then it hashes the combination of these two to finally obtain the resulting tag on the message M. So it's more rather looking into some symbols. It's more instructive to look at HMAC in pictures. And so you can see that here are the two keys k XOR inner-pad, which is then fed into the Merkle-Damgard chain. And then the resulting output of this chain is fed into another Merkle-Damgard chain and finally the final output is produced. Okay, so this is how HMAC works in pictures and now I want to argue that we've already seen something very similar to this.\n",
    "\n",
    "![HMAC In Pictures](http://cl.ly/Ti2P/Screen%20Shot%202014-02-04%20at%2001.47.50.png)\n",
    "\n",
    "ipad and opad are 512 bits constants. \n",
    "\n",
    "### Verification timing attacks\n",
    "\n",
    "Make sure that verification is constant time.\n",
    "\n",
    "1) Iterate through every set of bytes. Be careful of compiler optimisations!\n",
    "2) Compute correct MAC, we hash the correctly computed MAC again and then compare byte by byte. This way the attacker doesn’t know what is being compared!\n",
    "\n",
    "Lesson: Don’t implement your own crypto!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Week 4\n",
    "\n",
    "# Authenticated Encryption 1\n",
    "* So in previous segments, we talked about confidentiality, in particular how to encrypt messages such that we achieve semantic security against what's called a chosen plaintext attack. Now I kept mentioning again and again that security against chosen plaintext attacks only provides security against eavesdropping. In other words, this only provides security against adversaries that listen to network traffic. But don't actually change any packets, or don't inject their own packets, and so on. In this module, our goal is actually to design encryption schemes that are secure against adversaries that can tamper with traffic by blocking certain packets, and injecting other packets and so on. And then we also looked at how to provide message integrity where the message itself is not confidential. We just want to make sure that the message is not modified while it's en route. And so we talked about message authentication codes, MAC algorithms that provide existential unforgeability against a chosen message attack. In other words, even though the attacker is able to obtain the MACs on arbitrary messages of his choice, he can't build MACs for any other messages. And we looked at a number of MAC constructions, in particular CBC MAC, HMAC, a Parallel mac construction. And a fast MAC construction called a Carter-Wegman MAC. In this module, we're going to show how to combine these confidentiality and integrity mechanisms to obtain encryption schemes that are secure against a much, much stronger adversary, namely an adversary that can tamper with traffic while it's in the network, inject its own packets, block certain packets, and so on. And our goal is basically to insure that even against such powerful adversaries, we maintain confidentiality. In other words, the adversary can't learn what the plain text is and the adversary can't even modify the cipher text. And cause the recipient to think a different plain text was actually sent.\n",
    "\n",
    "**Confidentiality (CPA secure ciphers) without integrity cannot guarantee secrecy under active attacks.**\n",
    "\n",
    "* If message needs integrity but no confidentiality -> MAC. If message needs both integrity and confidentiality, use authenticated encryption modes.\n",
    "\n",
    "* Example of attack: Altering destination port of IP packet even if CPA secure cipher is possible by changing IV (if in CBC mode for instance).\n",
    "\n",
    "* Authenticated encryption  was introduced in 2000 but before then, many crypto libraries supported CPA-secure encryption and MAC. Every developer had to find his own \tway of combining both to provide AE.\n",
    "\n",
    "* So this nice example shows that without integrity it's simply impossible for a CPA secure encryption to provide confidentiality, when the attacker can modify packets en route. CPA secure encryption only provides confidentiality if the attacker is only eavesdropping on data, but can't actually modify a cipher text en route.\n",
    "* the lesson that I'm gonna repeat again and again and again throughout this module is that if your message needs integrity but no confidentiality, just use a MAC. But if your message needs integrity and confidentiality, you have to use what's called an authenticated encryption mode, So CPA security modes we discussed before should never actually be used to encrypt data by themselves. So CBC with a random IV is a building block towards authenticated encryption, but should never be used on its own.\n",
    "\n",
    "## Definition of Authenticated Encryption\n",
    "\n",
    "* **Authenticated encryption** is a cipher where as usual the encryption algorithm takes a key, a message and optionally a nonce and outputs a cipher text. The decryption algorithm as usual outputs a message. However, here the decryption algorithm is allowed to output a special symbol called bottom. When the decryption algorithm outputs the symbol bottom, basically it says that the cipher text is invalid and should be ignored. The only requirement is that this **bottom** is not in the message space so that in fact it is a unique symbol that indicates that the cipher text should be rejected.\n",
    "\n",
    "* An authenticated encryption system (E,D) is a cipher where \n",
    "\n",
    "    * **E:K x M x N -> C** \n",
    "    * **D: K x C x N -> M ∪ {ciphertext is rejected}.** \n",
    "\n",
    "* The system must provide both semantic security under a CPA attack and cipher text integrity (attacker cannot create new cipher texts that decrypt properly).\n",
    "* **The system has to satisfy two properties.**\n",
    "\n",
    "\n",
    "*  The first property is that it has to be semantically secure under a chosen plaintext attack\n",
    "*  But now there's a second property which says that the system also has to satisfy what's called cipher text integrity. What that means is that even though the attacker gets to see a number of cipher texts, it should not be able to produce another cipher text that decrypts properly. In other words, that decrypts to something other than bottom. \n",
    "\n",
    "\n",
    "* **Two implications of authenticated encryption.**\n",
    "\n",
    "\n",
    "*  The **first** I'll call authenticity, which means that, basically, an attacker cannot fool the recipient, Bob, into thinking that Alice sent a certain message that she didn't actually send. So let's see what I mean by that. Well, here, the attacker basically gets to interact with Alice, and get her to encrypt arbitrary messages of his choice. So this is a chosen plain text attack. And then the attacker's goal is to produce some cipher text that was not actually created by Alice. And because the attacker can't win the cipher text integrity game, he can't do this. What this means is, when Bob receives the cipher text that decrypts correctly under the decryption algorithm, he knows that the message must have come from someone who knows the secret key K. In particular, if Alice is the only one who knows K, then he knows the cipher text really did come from Alice, and it's not some modification that was sent by the attacker.\n",
    "* The **second** implication of authenticated encryption is that it defends against a very powerful type of adversary, namely an adversary that can mount what's called a chosen cipher text attack.\n",
    "\n",
    "    * Authenticated ciphers do provide:\n",
    "        * Authenticity: Attacker cannot fool Bob into thinking a message was sent from Alice. (doesn’t protect against replay/side channels attacks though)\n",
    "        * Security against chosen cipher text attack\n",
    "\n",
    "## Chosen cipher text security\n",
    "* In this segment I want to show you that authenticated encryption in fact is a very natural notion of security and I'll do it by showing you that it defends against a very powerful attack called a chosen cipher text attack. So in fact we already saw a number of examples of a chosen cipher text attack so imagine the adversary has some cipher text C that it wants to decrypt. And what it can do is, for example, fool the decryption server into decrypting some cipher text but not actually the cipher text c. So we already saw some examples of that. If you remember in the first segment, we looked at an adversary that can submit arbitrary cipher text, and if the plaintext happened to start with destination equals 25, then the adversary is actually given the plaintext in the clear. So that's an example of an adversary that can obtain the decryption of certain cipher texts but not all cipher texts. Another example we saw is an adversary that can learn something about the plaintext by submitting cipher texts to the decrypter. So we have this example where the adversary submits encrypted TCP/IP packets to the decryption server, and if the decryption server sends back an ACK, the adversary learns that the decrypted plain text had a valid check sum. And otherwise, the decrypted plain text didn't have a valid check sum. So this is, again, an example of a chosen cipher text attack, where the attacker submits cipher text, and learns something about the decryption of that cipher text\n",
    "\n",
    "    * Adversary’s power : both CPA and CCA\n",
    "        * Can obtain the encryption of arbitrary messages of his choice\n",
    "        * Can decrypt any cipher text of his choice other than the challenge\n",
    "        * Adversary goal : break semantic security.\n",
    "        * Let (E,D) be a cipher that provides authenticated encryption, then (E,D) is CCA secure. \n",
    "\n",
    "\n",
    "* So to address this type of threats, we're gonna define a very general notion of security, called chosen cipher text security. So here, we're gonna give the adversary a lot of power, okay? So he can do both chosen plain text attack, and a chosen cipher text attack. In other words, he can obtain the encryption of arbitrary messages of his choice. And he can decrypt any cipher text of his choice, other than some challenge cipher texts. And as I showed you before, this is actually a fairly conservative modeling of real life. In real life, often, the attacker can fool the, the decrypter, into decrypting certain cipher texts for the attacker, but not all cipher texts. So the model here is that the attacker has a certain cipher text that it wants to decrypt. It can interact with the decrypter by issuing these chosen cipher text queries to the decrypter. Namely, to decrypt various cipher text other than the challenge cipher text. And then the adversary's goal is to break semantic security of the challenge cipher text. So you notice that we're giving the adversary a lot of power. \n",
    "\n",
    "\n",
    "\n",
    "* **Chosen Plain Text Attack**\n",
    "So a chosen plain text query, as we already know. Basically, the adversary submits two messages, M zero and M1. They have to be the same length. And the adversary receives the encryption of either M zero if we're in experiment zero, or M1, if we're in experiment one. So he receives the encryption of the left or the right depending on whether we were in experiment zero or in experiment one.\n",
    "\n",
    "\n",
    "\n",
    "* **Chosen Cipher Text Attack**\n",
    "The second type of query is the more interesting one. This is where the adversary submits an arbitrary cipher text of his choice and what he gets back is the decryption of that cipher text. So you notice the adverary's allowed to decrypt arbitrary cipher texts of his choice. The only restriction is that the cipher text is not one of the cipher texts that were obtained as a result of a CPA query. And of course this wouldn't be fair otherwise, because the attacker can simply take one cipher text that was obtained from a CPA query. That's gonna to be either the encryption of M0 or the encryption of M1. If he could submit a CCA query for that particular cipher text, he will in response either obtain M0 or M1, and then he'll know whether he is in experiment zero or experiment one. So this wouldn't be fair. So we say that the CPA cipher texts that he received are the challenge cipher texts. And he's allowed to decrypt any cipher texts of his choice, other than these challenge cipher texts. And as usual, his goal is to determine whether he's in experiment zero, or in experiment one. \n",
    "\n",
    "\n",
    "* Okay, so as we said authenticated encryption ensures confidentiality. Even if the adversary can decrypt a subset of the cipher text, and more generally, even if he can mount a general chosen cipher text attack, he still is not going to be able to break semantic security of the system. However, it is important to remember the two limitations. First of all, it does not prevent replay attacks on its own. We're going to have to do something in addition to defend against replay attacks. We're going to see several examples where if the decryption engine reveals more information about why a cipher text is rejected, it doesn't just output bottom, but it actually outputs more information, say, by timing attacks. And that explains why the cipher text is rejected. Then in fact that can completely destroy security of the authenticated encryption system.\n",
    "\n",
    "# Authenticated Encryption 2\n",
    "\n",
    "# Combining MAC and ENC (CCA )Encrypt-then-Mac vs MAC-then-Encrypt\n",
    "\n",
    "\n",
    "So let's look at some combinations of CPA secure encryption and MAC, that were introduced by different projects. So here are three examples. So, first of all, in all three examples, there's a separate key for encryption, and a separate key for MACing. These two keys are independent of one another, and both are generated at session setup time.\n",
    "\n",
    "* Three approaches:\n",
    "* **MAC-then-Encypt (SSL)**:So the first example is the SSL protocol. So the way SSL combines encryption and MAC in the hope of achieving authenticated encryption is the following. Basically you take the plain text, m, and then you compute a MAC on the plain text, m. So you use your MAC key, kI, to compute tag for this message m. And then you can concatenate the tag to the message and then you encrypt the concatenation of the message and the tag and what comes out is the actual final cipher text. May be insecure against CCA attacks. If you’re using rand-CTR mode or rand-CBC, you have authenticated encryption. And for rand-ctr mode, one time MAC is sufficient.\n",
    "\n",
    "* **Encrypt-then-Mac (IPSec)**: The second option is what IPsec does. So here, you take the message. The first thing you do is you encrypt the message. And then, you compute a tag on the resulting cipher text. So you notice the tag itself is computed on the resulting cipher text. This is the favorite method. Because encryption provides confidentiality on the message and then the MAC algorithm provides the signing. Always correct. \n",
    "\n",
    "* **Encrypt and MAC (SSH)**: A third option is what the SSH protocol does. So here, the SSH takes the message, and encrypts it using a CPA secure encryption scheme. And then, to it, it concatenates a tag of the message. This means that MACs (of the message) are concatenated with the cipher text. This is an issue if the MACing algorithm reveals information about the plaintext. (MAC algorithms are not designed for confidentiality, only integrity). No issues with the specifics of SSL though but should really not be used.\n",
    "\n",
    "\n",
    "* The difference between IPsec and SSH, is that in IPsec, the tag is computed over the cipher text, whereas, in SSH, the tag is computed over the message. And so these are three completely different ways of combining encryption and MAC.\n",
    "\n",
    "\n",
    "## WHICH ONE IS SECURE ?\n",
    "\n",
    "##  SSL Approach\n",
    "\n",
    "*  For the **SSL** approach, there actually are kind of pathological examples, where you combine CPA secure encryption system with a secure MAC. And the result is vulnerable to a chosen cipher text attack, so that it does not actually provide authenticated encryption. And basically, the reason that could happen, is that there's some sort of a bad interaction between the encryption scheme and the MAC algorithm. Such that, in fact, there will be a chosen cipher text attack. \n",
    "\n",
    "##  IPsec\n",
    "\n",
    "* The recommended method actually is the **IPsec** method. Because it turns out no matter what CPA secure system and MAC key you use the combination is always gonna provide authenticated encryption. Now let me very, very briefly explain why. Basically what happens is once we encrypt the message well the message contents now is hidden inside the cipher text and now when we compute a tag of the cipher text basically we're locking, this tag locks the cipher text and makes sure no one can produce a different cipher text that would look valid. And as a result this approach ensures that any modifications to the cipher text will be detected by the decrypter simply because the MAC isn't gonna verify.\n",
    "\n",
    "## SSH\n",
    "\n",
    "* So let's start with the **SSH** method. So in the SSH method you notice that the tag is computed on the message and then concatenated in the clear to the cipher text. Now this is actually quite a problem because MACs themselves are not designed to provide confidentiality. MACs are only designed for integrity. And in fact, there's nothing wrong with a MAC that as part of the tag outputs a few bits of the plain text. Outputs a few bits of the message M. That would be a perfectly fine tag. And yet if we did that, that would completely break CPA security here, because some bits of the message are leaked in the cipher text. And so the SSH approach, even though the specifics of SSH are fine and the protocol itself is not compromised by this specific combination, generally it's advisable not to use this approach. Simply because the output of the MAC signing algorithm might leak bits of the message. \n",
    "\n",
    "### Standards\n",
    "\n",
    "All these modes are AEAD (auth enc. with associated data, partial encryption but fully authenticated) and nonce-based.\n",
    "\n",
    "- GCM (Galois counter mode - NIST): CTR mode encryption then CW-MAC. Recommended way to provide authenticated encryption if code size is not an issue (non-embedded systems).\n",
    "\n",
    "- CCM (CBC counter mode - NIST): CBC-MAC then CTR mode encryption (used for 802.11i) BASES on AES \n",
    "\n",
    "- EAX : CTR mode encryption then CMAC.\n",
    "\n",
    "* Now I wanted to mention that first of all, all these modes are nonce-based. In other words, they don't use any randomness but they do take as input a nonce and the nonce has to be unique per key. In other words, as you remember, the pair (key, nonce) should never ever, ever repeat. But the nonce itself need not be random, so it's perfectly fine to use a counter, for example, as a nonce. And the other important point is that, in fact, all these modes are what's called authenticated encryption with associated data.\n",
    "\n",
    "* What happens is in these three modes GCM, CCM, and EAX, basically the MAC is applied to the entire data. But the encryption is only applied to the part of the data that needs to be encrypted\n",
    "\n",
    "    * **MAC security**\n",
    "\n",
    "* I can explain to you something that might have been a little obscure when we looked at that definition. So if you remember, one of the requirements that followed from our definition of secure MACs meant that given a message-MAC pair on a message M, the attacker cannot produce another tag on the same message M. In other words, even though the attacker already has a tag for the message M, he shouldn't be able to produce a new tag for the same message M. And it's really not clear, why does that matter? Who cares, if the adversary already has a tag on the message M, who cares if he can produce another tag? Well, it turns out if the MAC didn't have this property. In other words, given a message-MAC pair you can produce another MAC on the same message, then that MAC would result in an insecure encrypt-then-MAC mode. And so if we want our encrypt-then-MAC to have cipher text integrity, it's crucial that our MAC security would imply this strong notion of security, which, of course, it does because we defined it correctly.\n",
    "\n",
    "### New constructions OCB \n",
    "\n",
    "* After authenticated encryption got formalised. People started thinking about newer constructions that would provide AE without combining an encryption mode and a MAC algorithm. OCB is an example of that. OCB is parallelizable. Sadly, OCB is not used because of patents :(\n",
    "\n",
    "\n",
    "\n",
    " \n",
    "# TLS : How TLS record works\n",
    "* Overall TLS 1.2\n",
    "\n",
    "* So data encryption in TLS is done using a protocol called a TLS record protocol. In this protocol, every TLS record starts with a header, we'll see the structure of the header in just a minute, followed by encrypted data that is sent from one side to the other. In TLS, it so happens that the records are at most sixteen kilobytes and if more data than sixteen kilobytes needs to be sent, then basically the record is fragmented into multiple records. Now TLS uses what's called unidirectional keys, meaning that there's one key from browser to server, and there's a separate key from server to browser. So one key is used for sending messages from a browser to the server, and the other key is used from sending messages from the server to the browser, and of course both sides, both the server and the browser, know both of these keys. And just to be clear I'll say the browser will use this key to send data to the server and we'll use this key to read data from the server and the server basically does exactly the same thing just with the opposite keys. Now these keys, both of these keys are actually generated by the TLS key exchange protocol which we're gonna talk about in the second part of the course. Right now I'm gonna assume that these keys have already been established. They're known to both the server and the browser, and now the browser and server want to exchange information using those keys. So the TLS record protocol uses what's called stateful encryption, which means that the encryption of every packet. Is done using certain state that's maintained inside of the browser and the server. In particular the state that's of interest to us are these 64 bit counters, again there are two 64 bit counters. One for traffic from browser to server, and one from traffic from the server to the browser. These counters are initialized to zero when the session is first initialized, and they're incremented every time a record is sent. So every time the browser sends a record to the server, the browser will go ahead and increment this counter. When the server receives that record, it'll go ahead and increment the counter on its side. And when the server sends a record to the browser, he'll go ahead and increment the second counter and again when the browser receives this record it'll go ahead and increment its copy of this counter. So this state these two counters basically this state exists both on the browser and on the server and it's updated appropriately as records as sent from one to the other and received by the appropriate side. Now the purpose of these counters as we'll see in just a minute is to prevent replay attacks so than an attacker can't simply record the record and then replay at a later time because by then the counters will have to be incremented.\n",
    "\n",
    "    * Okay, so let's look at the details of how the record protocol works. In particular I'll show you kind of the mandatory cipher suit which is encryption using AES-CBC and MACing using HMAC-SHA1. Okay, so remember, TLS uses a MAC, then encrypt, where the MAC algorithm is HMAC-SHA1, and the encryption algorithm is AES128 in CBC mode.\n",
    "    \n",
    "### Encryption Record\n",
    "* **Step 1** Okay, so let's look at how the browser sends data to the server, which, as I said, is done using the browser to server key. Now, the browser to server key itself, is made up of a MAC key and an encryption key. Two separated keys that are again as I said negotiated during session setup. And again I wanna be absolutely clear. There is a separate key for browser to server and a separate key from server to browser. So there, overall, there are four keys. Two MAC keys, and two encryption keys, each one used in the appropriate direction. Okay, so here I wrote down the diagram of what a tls packet looks like. It begins with a header that contains the type of the packet, the version number for the protocol, and the length of the packet. Notice the length of the packet it sends in the clear. Now, when the encrypting data, a certain record, the encryption procedure works as follows. Of course, it takes key as input, and it takes the current status input. And then it works as follows. What it'll do is first of all is it would MAC the following data, while here's the actual payload that's MACed but the heather is also MACed. In addition the counter, the current value of the counter is also MACed and of course, it's all the counters implemented during the  fact that one more record has been sent. Now the interesting thing here is that even though the value of the counter is included in the tag. You notice the value of the counter is actually never sent in the record, and the reason it doesn't need to be sent in the record is that the server on the other side already knows what the value of the counter needs to be. So it doesn't need to be told in the record what the value of the counter is. It implicitly already knows what it is, and when it's gonna verify the MAC, it could just use the value that it thinks the counter should be and verify the MAC in that fashion. Okay, so this is kind of an interesting approach, where even though the two sides maintain these counters that function as nonces, there is no reason to send the nonces in the record, because both sides actually already know what counters they're expecting every record that they receive. \n",
    "\n",
    "\n",
    "* **Step 2** The next thing that happens is that the tag is concatenated to the data. Remember, this is MAC-then-Encrypt. So here, we computed the MAC. Now we're gonna encrypt the data along with the tag. So the header, the data, and the tag are padded to the AES block, and I think we already said that this pad, if the pad length is five, then the pad is done by simply writing the byte five, five times. If the pad link leads to B5, the pad would just be 55555.\n",
    "\n",
    "* **Step 3** And then we CBC encrypt using the encryption key, we CBC encrypt the data and the tag. And we do that using a fresh random IV, which is later embedded in the cipher text.\n",
    "\n",
    "* **Step 4** And then we prepend the header, the type, the version and the length. And that gives us the entire TLS record, which is then sent over to the server.\n",
    "\n",
    "### Decryption Record\n",
    "\n",
    "* **Step 1** The server is going to use it's own key that corresponds to data, from browser to server. And it's own browser to server counter. And the first thing it's going to do, is it's going to decrypt the record using the encryption key. \n",
    "\n",
    "\n",
    "* **Step 2** After encryption, it's going to check the format of the pad. In other words, if the pad length is five bytes, it's going to check that it really is five, five, five, five, five. And if it's not, it's gonna send a bad record mac alert message and terminate the connection. So that a new session key will have to be negotiated if more records need to be sent.If the pad format is correct, then removing the pad is really easy. All the server does is it looks at the last byte of the pad, say the last byte is equal to five, and, then, it removes the last five bytes of the record. By doing that it strips off the pad.\n",
    "\n",
    "\n",
    "* **Step 3** The next thing it's gonna do is it's gonna extract the tag from the record. So, this would be the web sequence bytes inside of the record. So, this would be the, the trailing bytes in the record after we remove the pad, and then it's gonna verify the pad on the header, the data and its value of counter. And if the Mac doesn't verify again, it's gonna send an alert, bad record Mac, and tear down the connection. And if the pad does verify, it's gonna remove the tag, remove the header, and the remaining part of the record is the plain text data that's given to the application. \n",
    "\n",
    "\n",
    "## WEP\n",
    "\n",
    "* Basically there's a message that the laptop wants to send to the access point. The first thing that happens is it, the laptop computes a cyclic redundancy checksum on the message and concatenates the CRC checksum to the message. Then the result is encrypted using a stream cipher, in particular RC4. If you recall, the key that's used is the concatenation of an initial value IV that changes per packet and the long term key K. And then the IV along with the cipher text are transmitted to the other side. Now we've already saw two problems with this approach. One was if the IV is ever repeated and in fact it is gonna be repeated then you get a two time pad attack. And the other problem is that uses very closely related keys. In other words, the key is simply IV concatenated to K and the only thing that changes are the IV so the key is always fixed, which means that these PRG keys are very closely related to one another and as we said, the PRG that's used here, RC4 is not designed for this type of use and it completely breaks if you use it with related keys, and as a result WEP has no security at all. \n",
    "\n",
    "\n",
    "* **Active Attacks on WEP** CRC checksum is there to make sure that exactly the attacker cannot change data inside of the cipher text. But I want to show you that in fact it's really easy to modify data in the cipher text and CRC basically provides no security against tampering at all. So let's see how to do it. Well, what the attacker would do is, he would basically Xor some, a certain value XX into the byte that represents the eight zero in the cipher text. Now what he'll Xor in will basically be the string 25 Xor 80 and you remember that if I Xor a certain string XX into the cipher text. That was created using a stream cipher. When that cipher gets, is decrypted, the plain text at this position will also be Xored by XX. And as a result after decryption the plain text at this position basically will be the original 80XR 25 XR 80 which gives us 25. Okay? So after decryption the plain text of this position will now be 25. The problem is that if that's all we did then this attack would fail because the CRC check sum would now would not validate. The CRC check sum. Was built with 80 as a plain text but 25 is a different plain text and needs a different CRC. But it's not a problem because what we can do is we can easily correct the check sum, the CRC check sum, even though the CRC check sum is encrypted. What we do is we XOR F of XX into the cipher text at the place where the CRC is supposed to be and as a result, when the cipher text is decrypted what will happen is we'll get the correct CRC check sum after decryption. So, the interesting thing that happened here is even though the attacker doesn't know what the crc value is, he's able to correct it using this linearity property such that when the cipher text is decrypted the correct crc value appears in the plain text. Okay? So the linearity property of CRC plays a critical role in making this attack works. The end conclusion here is basically that a CRC check sum provides absolutely no integrity at all against active attacks and it should never, ever, ever be used as an integrity mechanism. And instead if you want to provide integrity you're supposed to use a cryptographic mac not an ad hoc mechanism like CRC.\n",
    "### Avoiding implementation mistakes\n",
    "\n",
    "Encrypt-then-MAC would completely avoid issues of MAC verifications in TLS because the MAC is checked first and ciphertext discarded if invalid. MAC-then CBC provides AE but padding oracle destroys it. \n",
    "\n",
    "\n",
    "\n",
    "# Authenticated Encryption 3 (CBC Padding Attacks)\n",
    "* **Authenticated Encryotion: ** CPA Security + Ciphertext security Integrity\n",
    "    * Provides Confidentiality in presence of active adversary\n",
    "    * Prevents chosen plain-ciphertext attacks\n",
    "    \n",
    "        * Limitation: Cannot help bad implementations\n",
    "\n",
    "* So recall that **authenticated encryption** means that the system provides CPA security plus cipher text integrity. And authenticated encryption means that we can preserve confidentiality in the presence of an active adversary, and moreover, the adversary can't modify the cipher text in any way without being detected. \n",
    "* We also showed that authenticated encryption prevents these very powerful chosen cipher text attacks. \n",
    "    * Unfortunately, authenticated encryption has a pretty significant limitation in that it simply can't help a bad implementation. If you implement authenticated encryption incorrectly, then your implementation will be vulnerable to active attacks. \n",
    "\n",
    "* In practice, you should just be using one of these three standards. You shouldn't try to implement authenticated encryption by yourself, and I hope that the attack that I'll show you in this segment convinces you that this is not something you should do yourself. Just use one of GCM, CCM or EAX. However, it's good for you to know that in general, when you want to provide authenticated encryption, the correct way to do things is encrypt, then MAC, because then no matter which encryption and MAC algorithms you combine. The result will be authenticated encryption, again assuming the encryption and Mac algorithm are implemented correctly.\n",
    "\n",
    "* There are two types of errors in TLS decryption. \n",
    "    * One is a padding error and one is a \n",
    "    * MAC error. \n",
    "        * It's very important that the adversary not be told which of these errors occurred.\n",
    "        \n",
    "* **WHY ?** (The padding oracle Occurs due to different alert error messages)\n",
    "* So, suppose an attacker can actually differentiate the two types of errors. In other words, he can tell if a pad error occurred, or a Mac error occurred. The result is what we call the padding oracle. ?Cause now, imagine the adversary has a certain cipher text that it intercepted. And it wants to try and decrypt that cipher text. What it could do, is it could take that cipher text as is, and submit it to the server. The server is gonna decrypt the cipher text and then look to see if the pad has the correct format. If the pad doesn't have the correct format, we'll get one type of error. If the pad has the correct format, it's very likely since this is just some random cipher text that the adversary concocted himself, it's very likely the mac will be incorrect, and then the adversary will observe a mac error. So if the pad is invalid, we'll see a pad error, whereas if the pad is valid we'll see a mac error. As a result, the adversary, after submitting the cipher text to the server, the adversary can tell whether the last bytes in the decrypted cipher text have a valid pad or not. In other words, whether the last bites in the decrypted cipher text are end with one. Or 2-2, or 3-3-3, or 4-4-4-4, and so on. So the adversary learns something about the decrypted cipher text, just by submitting the cipher text to the server. So this is a beautiful example of what's called a chosen cipher text attack. Where again, the address that you submit the cipher text and then he gets to learn something about the resulting plain text. \n",
    "\n",
    "* The problem is that when TLS receives a record with a bad pad or a bad Mac, it shuts down the connection, and renegotiates a new key. As a result, the attacker is now stuck with a cipher text encrypted using an old key. And that key is no longer used anywhere, so it cannot submit any more queries. So with TLS, basically, it can only submit one query, and that's it. Even a single query still leaks information about the plain text to the attacker. But it doesn't expose the entire plain text block m1. However this attack is so acute that whenever there's a mistake like this in a protocol there will be some settings in which it comes up and in this case the setting is in the case of an imap server. So imap is a popular protocol for reading email from an imap email server, and it's very common to protect the imap protocol by running it on top of a tls protocol. Now, it turns out an imap. Every five minutes, the IMap client will connect to the IMap server, and check whether there's new email. And the way it does it is by first logging in to the IMap server, by sending this login username password message. And then it goes ahead and check if there's new email available. Well, what this means is that every five minutes, the attacker gets an encryption of exactly the same message in particular, I guess, an encryption of the password. And so every five minutes, it can mount one guess on the block that contains the password. And so, if your password is eight characters long, the attacker simply needs to recover those eight characters. And he's gonna recover them one byte at, at a time, by doing one guess per five minutes. And so Canvel et. al. showed that, within a few hours, you can basically recover the user's password. Just by mounting one guest every five minutes. So this is a pretty significant attack against an implementation of TLS and the defense against this was to always check the Mac, whether the pad is valid or invalid. And as a result it takes the same amount of time to respond whether the pad is valid or invalid. So this removes the timing attack and makes this attack much harder to mount. \n",
    "        \n",
    "        \n",
    "### Attacking non-atomic decryption\n",
    "\n",
    "* The attacker can “stream” the bits of the ciphertext and then see when the MAC is verified because it’s probably going to be false and hence learn the first LSB of a message.\n",
    "\n",
    "*  So SSH is a standard secure remote shell application that uses a protocol between a client and the sever. It has a key exchange mechanism and once two sides exchange keys, SSH uses what's called the binary packet protocol to send messages back and forth between the client and the server. Now here is how SSH works, so recall that SSH uses what we called encrypt-and-MAC. Okay so technically what happens is every SSH packet begins with a sequence number, and then the packet contains the packet length, the length of the CBC pad, the actual payload follows, then the CBC pad follows. Now this whole red block here is CBC encrypted also with a chained IV, so this is also vulnerable to the CPA attacks that we discussed before. But nevertheless, this whole red packet is encrypted using CBC encryption. And then the entire clear text packet is MAC-ed. And the MAC is sent in the clear, along with the packet. So I want you to remember that the MAC is computed over plain text packets, and then the MAC is sent in the clear. This is what we call encrypt-and-MAC. And we said that this is not a good way to do things, because MACs have no confidentiality requirements. And by sending the MAC of the clear text in the clear, you might be exposing information about the clear text. But this is not the mistake that I want to show you here. I want to show you a much more clever attack. So first, let's look at how decryption works in SSH. So what happens is, first of all, the server decrypts the encrypted packet length field only. So it only decrypts these particular first few bytes. Then it will go ahead and read from the network, as many bytes as specified in the packet length field. It's gonna decrypt the remaining cipher text blocks using CBC decryption. Then, once it's recovered the entire SSH packet, it will go ahead and check the MAC of the plain text, and report an error if the MAC happens to be invalid. Now the problem here is that the packet length field is decrypted and then used directly to determine the length of the packet before any authentication has taken place. In fact, it's not possible to verify the MAC of the packet length field because we haven't recovered the entire packet yet and as a result we cannot check the MAC. But nevertheless the protocol uses the packet length before verifying that the MAC is valid.\n",
    "\n",
    "\n",
    "Lesson: Never partially decrypt ciphertext, always take blocks.\n",
    "    \n",
    "        \n",
    "# Ods and Ends 1: How to derive Keys (Key Derivation)\n",
    "\n",
    "* So the first thing I'd like to mention is how we derive many keys from one key. And it, actually, this comes up all the time in practice, so I'd like to make sure you know how to do this correctly. So what's the setting that we're looking at? Well, imagine we have a certain source key that's generated by one of, a number of methods. Imagine the source key is generated by a hardware random number generator or perhaps is generated by a key exchange protocol which we're going to discuss later. But anyhow, there are a number of ways in which a source key might be generated between Alice and Bob, such that the attacker doesn't know what the source key is. But now, as we said, in many cases, we actually need many keys to secure a session, not just one single source key. For example, if you remember, in TLS there were unidirectional keys and we needed keys in each direction. And in fact, in each direction, we needed multiple keys. We needed a MAC key, we needed an encryption key. We need an IV, and so on. Similarly nonce based encryption, you remember, there were multiple keys that were being used, and so on. And so, the question is, how do we use the one source key that we just derived, either from a hardware process or by key exchange, and generate a bunch of keys from it that we could then use to secure our session. The way that's done, is using a mechanism called a key derivation function, KDF.\n",
    "\n",
    "\n",
    "### KDF \n",
    "\n",
    "F: A PRF with key space K and outputs in {0.1}^n\n",
    "\n",
    "```\n",
    "Suppose source key SK is uniform in K\n",
    "    • Define  Key Derivation Function (KDF) as:\n",
    "    KDF(SK, CTX, L) :=\n",
    "        F(SK, (CTX || 0)) || F(SK, (CTX|| 1)) || •••|| F(SK(CTX || L))\n",
    "     CTX : a string that uniquely identifies the application\n",
    "    \n",
    "    SK = Sourece Key\n",
    "    L = Length\n",
    "```\n",
    "\n",
    "\n",
    "* How KDF's are constructed. So first of all, suppose we have a secure PRF, that happens to have key space K. And now, suppose that it so happens that our source key SK is uniform in the key K. In this case, the source key is, in fact, a uniform random key for the secure PRF F. And we can use it directly to generate keys, all the keys that we need to secure the session. So in this case, the KDF is really simple. The key derivation function would just work as follows. It would take as input the source key. It would take an input, a parameter context, which I'm gonna describe in just a minute. And then it's gonna take a length input as input as well. And then what it will do is it will basically evaluate the PRF on zero. Then it will evaluate the PRF on one. Then it will evaluate the PRF on two, up until L. And I will talk about what this context is in just a second. And then, basically, you would use as many bits of the output as you would need to generate all the keys for the session. So, if you need unidirectional keys you would generate, you know, one key in each direction where each key might include an encryption key and a MAC key. And so, you would basically generate as many bits as you need and then finally cut off the output at the time when you've generated enough keys to secure your session. Okay so this is a fairly straight forward mechanism it's basically using the secure PRF as a pseudo random generator. And the only question is what is its context string. Well, I'll tell you that the context string is basically a unique string that identifies the application. So in fact you might have multiple applications on the same system that's trying to establish multiple secure keys\n",
    "\n",
    "* **Context Variable** : Context string is basically a unique string that identifies the application, thus even if two apps sample same SK they get independent keys. It does need to be specific to the application so that each application get its own session keys, even if multiple applications happen to sample the same SK. \n",
    "* So in fact you might have multiple applications on the same system that's trying to establish multiple secure keys. Maybe you have SSH running as one process, you have a web server running as another process, IPsec as a third process and all three need to have secret keys generated. And this context variable basically tries to separate the three of them.\n",
    "\n",
    "* **What if the keys are not Uniform**\n",
    "    * Recall: PRF's are pseudo random only when key is uniform in K\n",
    "        * SK not uniform = PRF output may not look random\n",
    "        \n",
    "    * Source Key Often not uniformly random:\n",
    "        * Key Exchange Protocol: Key Uniform in subset of K\n",
    "        * Hardware RNG: May produce biased output\n",
    "        \n",
    "* Now why would this source key not be uniform? Well there are many reasons why this happened. For example if you use a key exchange protocol, it so happens typically that key exchange protocols will generate a high entropy key. But the high entropy key is gonna be distributed in some subspace of the key space. So it's not going to be a uniform string. It will be uniform in some subset of a larger set, And we'll see examples of that as soon as we talk about key exchange protocols. And so KDFs have to kind of accommodate for the fact that key exchange protocols actually don't generate uniform bit strings. The other problem is, that, in fact, the hardware random number generator you're using might actually produce biased outputs. We don't wanna rely on the non bias of the hardware random number generator.\n",
    "\n",
    "\n",
    "* **Extract-then-Expand paradigm**\n",
    "    * Step 1 Extact psuedo *random key* **k** from *source key* **SK**\n",
    "    \n",
    "* **A salt is a fixed non-secret string chosen at random and it jumbles things around so  that no matter what the input distribution is, the output distribution is still going to be indistinguishable from random**\n",
    "    * Step 2 Expand k using it as a PRF key before (Expand it into as many keys as we need using a psuedo random function)\n",
    "* The extract-then-expand paradigm, where the first step of the KDF is to extract a pseudo random key from the actual source key. So in a picture you can think about it like this. In some sense these are the different possible values of the source key. This is the horizontal line and the vertical axis is basically the probability of each one of these values, and you can see that this is a kind of a bumpy function which would say that the source key is not uniformly distributed in the key space. What we do in this case is we use what's called an extractor. So an extractor is something that takes a bumpy distribution and makes it into a uniform distribution over the key space. \n",
    "\n",
    "### Example HKDF: A KDF form HMAC\n",
    "* So the standardized way of doing this is called HKDF. This is a KDF, a key derivation function that's built from HMAC. And here HMAC is used both as the PRF for expanding and an extractor for extracting the initial pseudo-random key\n",
    "\n",
    "* Implements the extract-then-expand paradigm:\n",
    "* So in the extract step, we're gonna use our salt which you remember is a public value just happened to be generated at random at the beginning of time. And we use this salt as the HMAC key. And then the source key we're gonna use as the HMAC data.\n",
    "    * Extract: Use \n",
    "```\n",
    "k <---  HMAC(salt, SK)\n",
    "```\n",
    "\n",
    "* Then expand using HMAC as PRF with key **k**\n",
    "* And now that we have the pseudo random key we're simply going to use HMAC as a PRF to generate a session key of you know as many bits as we need for the session keys. \n",
    "\n",
    "\n",
    "\n",
    "### Password-Based KDF (PBKDF)\n",
    "* Deriving keys from passwords:\n",
    "    * Do not use HKDF : Passwords have insufficient entropy\n",
    "    * Derived keys will be vulnerable to dictionarry attacks\n",
    "    \n",
    "* PBKDF defenses: salt and a slow hash function\n",
    "* Standard Approach: **PKCS#5**\n",
    "```\n",
    "(H)^c(pwd || salt): Iterate hash function c times\n",
    "```\n",
    "\n",
    "* How do you extract keys from passwords. These are called password based KDFs or PBKDFs.The problem here is that passwords have relatively low entropy. \n",
    "* Passwords generally have very little entropy estimated on the order of twenty bits of entropy, say. And as a result, there is simply not enough entropy to generate session keys out of a password.\n",
    "\n",
    "* All crypto libraries have an implementation of a PKCS#5 mechanism. And you would just call the appropriate function to convert a password into a key, and then use the resulting key. \n",
    "\n",
    "\n",
    "# Deterministic Encryption Odds and Ends 2 (Searching on encrypted data)\n",
    "## The need for encryption (no nonce)\n",
    "\n",
    "* When I say deterministic encryption system, I mean an encryption system that will always map given message to exactly the same cipher text. So if we encrypt the same message three times, every time we'll get exactly the same cipher text. So there are no nonces involved here. Literally this is just a consistence encryption scheme that will always output the same cipher text given a particular message.\n",
    "\n",
    "* So let's see where this comes up in practice and in particular, I want to show you the case of look-ups into an encrypted database. So the settings are imagine we have a server here that is going to store information inside of an encrypted database. So what it will store is records, and every record has an index and some data that's stored inside of the record. Now, the first thing the server's gonna do is, it's gonna encrypt this record. So here's a record became encrypted and you notice that the index became encrypted with K1 and the data is encrypted with K2 and then the encrypted record is sent over to the database. And the same thing happens to many records so that the database overall holds many, many encrypted records. Well, again, you can imagine that the index is encrypted using the key K1 and then the data and the records is encrypted using the key K2. Now, if encryption is deterministic, the nice thing about that is that, at a later time, when the server wants to retrieve a record from the database, all he needs to do is send to the database an encryption of the index that the server is interested in. So here, it would send an encryption of the index, Alice. That again, becomes encrypted, and the resulting cipher text is identical to the cipher text that was generated when the record was first written to the database. And the database can then, you know, find the record that has this encrypted index in it, and then send the result back to the server. The nice thing about this is that now the database is completely in the dark as to what data is stored in the database and it doesn't even know what records are being retrieved by the server since all it sees are basically requests for encrypted entices. And so this deterministic encryption mechanism. Let's just do a quick look up in the database given an encrypted index and we're guaranteed that because of the deterministic encryption property that the index is going to be encrypted in exactly the same way as if was when the record was created.\n",
    "\n",
    "* **The prblem:** By looking at multiple ciphertext, the attacker can tell when two ciphertexts encrypt the same message and this could leak some message.\n",
    "    * This also leads to significant attacks when message space M is small.\n",
    "    * For example, if we're transmitting single bytes across the network, such as, keystrokes that are being transmitted one keystroke at a time. Then, in fact, an attacker can simply build a dictionary of all possible cipher texts.\n",
    "* **The solution:** is basically to restrict the type of messages that can be encrypted under a single key. And so, the idea is to say that suppose the encryptor never ever, ever encrypts the same message under a single key. In other words the message key pair is always different and never repeats. So that for every single encryption, either the message changes, or the key changes, but, or both change. But it can't be that we encrypt the same message twice under the same key.\n",
    "\n",
    "* **if you need to encrypt the database index in a consistent manner, don't use CBC with a fixed IV to do it.**\n",
    "## Synthetic IV \n",
    "\n",
    " * So, first let me remind you that the deterministic encryption is needed, for example, when encrypting a data base index and later we wanna look up records using the encrypted index. Because the encryption is deterministic we're guaranteed that when we do the lookup the encrypted index is gonna be identical to the encrypted index that was sent to the database when the record was written to the database. And so, this deterministic encryption allows us a very simple or fast way to do lookups based on encrypted indices. The problem was that we said the deterministic encryption can't possibility be secure against a general chosen plaintext attack because if the attacker sees two cipher texts that are equal it learns that the underlying encrypted messages are the same. So, then we defined this concept of deterministic chosen plain text security which means that we have security as long as the encryptor never encrypts the same message more than once using a given key. In particular, this key, message pair is only used once, for every encryption, either the key changes, or the message change\n",
    "\n",
    "* Dae. Deterministic Authenticated Encryption. Which basically means that deterministic CPA security and cipher text integrity. Remember cipher text integrity means that the attacker gets to ask for the encryptions of messages of his choice and then he shouldn't be able to produce another cipher text that decrypts to a valid message. Okay, so I want to claim that in fact SIV automatically gives a cipher text integrity without the need for an embedded MAC or anything else. So let's see why. In particular, let's look at a special case of SIV when the underlying encryption scheme is randomized counter mode. Okay, so we'll call this SIV-CTR again to denote SIV where we're using randomized counter mode. Alright. So let me remind you again how SIV works in this case. Well, so we take our message, here, we take our message, and then we apply a PRF to it. And that derives an IV. And then that IV is going to be used to encrypt the message using randomized counter mode. Okay. So in particular, we're gonna use this PRF FTCRr for F counter, for randomized counter mode and essentially evaluate this FCTR at Iv, IV plus one up to IV plus L. And, then, we had sorta that with the message. And that gives us the final ciphertext. Okay. So, this is SIV with a randomized counter mode. Now, let's see how decryption is gonna work. And during decryption we're gonna add one more check, and that's going to provide ciphertext integrity. So let's see how decryption is going to work. So here we have our input cipher text that contains the IV and the cipher text. Well, the first thing we're going to do is we're going to decrypt the cipher text using the given IV, and that will give us candidate plain text. Now we're gonna reapply the PRF F from the definition of SIV to this message. Now if a message is valid, we should be getting the same IV that the supplied as part of the cipher text. If we get a different IV, then we know that this message is not a valid message and we simply reject the cipher text. So this is really cute. It's a very simple kinda built in check to make sure that the cipher text is valid, right. We simply check that after decryption if we re-derive the IV we would actually get the correct IV. And if not we reject the message. And I claim that this simple check during decryption is enough to provide ciphertext integrity. And therefore, deterministic authenticated encryption. \n",
    "\n",
    "* **PRP construction is very good for short messages, whereas SIV is good if you h, if you want to encrypt longer messages in a deterministic fashion.**\n",
    "\n",
    "\n",
    " * I wanted you to see these two very cute deterministic authenticated encryption schemes. The first one we called SIV, where I said you would use randomized counter mode and you just arrived at randomness for randomized counter mode from a PRF applied to the message. And the very cute idea here is that during decryption you can simply recompute the IV from the, from the decrypted message and verify that that IV is what's given to you in the cipher text. And that simple check is actually enough to guarantee authenticated encryption or rather deterministic authenticated encryption. So this mode is, is the way you would encrypt an index in a database if the index was large. If the index happens to be short, maybe say, its eight bytes if it's an 8-byte user ID, then you can directly use a PRP and the way you would do is, is you would append zeros to those eight bytes. And then those zeros will be used as an integrity check when you decrypt and again if you append, are able to append enough zeros, then in fact this also provides deterministic authenticated encryption\n",
    " \n",
    " \n",
    " \n",
    " \n",
    "# Odds and Ends 3 Disk ENcryption (Tweakable Encryption)\n",
    "\n",
    "* So the disk encryption problem is that we wanna encrypt sectors on disks.\n",
    "\n",
    "* Say each sector is four kilobytes long. And the problem is that there's no space to expand. In other words, if the sector size is four kilobytes, the cipher text size also has to exactly four kilobytes because there's nowhere to write the extra bits if the cipher text was bigger than the plain text. And so our goal is basically to build a non-expanded encryption where the cipher text size is identical, exactly equal to the plain text size. So what does it mean that encryption can't expand? Well, technically, we're saying basically the message space is equal to the cipher text space, so the message space would be four-kilobyte messages and the cipher text space would be also four-kilobyte messages. In this case, clearly we have to use deterministic encryption, because if encryption was randomized, there would be no place to store the randomness. And similarly, we have no room for integrity because we can't expand a ciphertext and add any integrity bits. So the most we can achieve is deterministic CPA security and that's gonna be our goal. Now it turns out, there's a really simple lemma to prove that basically says, that if you give me a deterministically CPA secure cipher, where the message space is equal to the cipher text base, so no expansion. Then in fact, the cipher is a PRP. So really all we're saying here is if we want no expansion at all, our only option for encrypting is what we called construction number two in the previous segment. Namely, we have to encrypt using a PRP. So let's look at how we might encrypt using a PRP while we take our disk and we break it into sectors\n",
    "\n",
    "\n",
    "* Now this actually is a real problem. For example, if some of your sectors are empty, you know they're all set to zero, then in fact, the crypted sectors would be identical, and as a result, the attacker would know exactly which sectors on your disk are empty and which sectors are not. So, this is actually quite problematic and the question is, can we do any better? And so the answer is yes. And the first idea that comes to mind is, well, why don't we use a different key for every sector? So you can see sector number one gets encrypted with key one, sector number two gets encrypted with key two and so on and so forth. So now even if the content of sector number one is equal to sector number three the cipher texts of sector 1 and sector 3 will be different because they are encrypted under different keys. So this actually avoids the leakage that we talked about before, although I do want to point out there is still a little bit of leakage with this mode, for example if the user happened to change 1 bit in sector 1. And then that sector gets encrypted into a different cyphodext so this will be garbled all completely because this is a pseudorandom permutation. The sector will be even if one bit of the plaint exchanges, the sector will just be mapped to a completely new random output. However if the user then undoes the change and reverts back to the original sector, then the encrypted sector will revert back to its original state. And the attacker can tell that a change was made and then reverted, so there is still a little bit of information leakage but that type of information leakage is really nothing we can do without really sacrificing performance so we are just going to ignore that and deem that acceptable\n",
    "\n",
    "### Example 1 \n",
    "*  So let's look at some examples. So we already looked at the trivial example. In the trivial example, what we do, we're gonna assume that the key space is equal to the input space. So this PRP really acts on x times x to x. \n",
    "* So think of AES, for example, where the key space is 128 bits, the data space is 128 bits, and of course, the output is 128 bits. And then the way that we define the tweakable blocks. There's a key, a tweak, and data as input. Is basically we encrypt the tweak using our master key and then we encrypt the data using the resulting random key. Now you realize that if we wanted to encrypt n blocks with this tweak of block cypher, this would require two n evaluations of the block cypher. N evaluations to encrypt the given tweaks and then, and more evaluations to encrypt the actual given data. \n",
    "\n",
    "### Example 2\n",
    "* XTS\n",
    "* So just to summarize, the way XTS is used for disk encryption. What we do is, we look at sector number t and we break it into blocks, 16 byte blocks. And then block number 1 gets encrypted with a tweak (t,1), block number 2 gets encrypted with a tweak (t,2), and so on and so forth. And so every block gets it's own PRP and the whole sector, as a result, is encrypted, using a collection of PRP's. Now, you notice, this is a block level PRP, it's not a sector level PRP. So, in fact, it's not true that each sector gets encrypted with it's own PRP. It's just each block gets encrypted with it's own PRP. The distinction would be the sector in a block is somewhat artificial, and this XTS mode actually provides the terministic CPA encryption at the block level, at the sixteen byte level, that's the goal. And this mode actually is fairly popular in disk encryption products\n",
    "\n",
    "### Summary\n",
    "* So to summarize, tweakable encryption is a useful concept to know when you need many independent prp's all derived from a single key.\n",
    "* One important thing to remember is in fact the trivial construction is not the most efficient. There are constructions like XTS, are actually more efficient, where he can kind of reuse encryptions from one tweak, to get many encryptions for many different tweaks.\n",
    "* Both the trivial construction and the XTS construction are, what I call narrow block constructions. Namely they provide a tweakable block ciphers for a 16 byte block.\n",
    "* But, as we said, we looked at the EME construction in the last segment, which provided a PIP for much larger blocks. And in fact, EME is a tweakable mode of operation. So if you need PIPs for larger blocks or tweakable PIPs for larger blocks, then you would just use EME. But you notice there EME, you have to apply the block size for twice per in per block. And as a result, it's twice as low as XTS and is not very often used.\n",
    "\n",
    "\n",
    "# Odds and Ends 3 (Format preserving Encryption)Creditcard Encryption\n",
    "\n",
    "* encrypting credit card numbers.\n",
    "* Remember that a typical credit card number is sixteen digits, broken into four blocks of four digits each.\n",
    "* You've probably heard before that the first six digits are what's called the BIN number, which represent the issuer ID. For example, all credit cards issued by VISA always start with the digit four; all credit cards issued by MasterCard start with digits 51 to 55, and so on and so forth.\n",
    "* The next nine digits are actually the account number that is specific to the, to the particular customer and the last digit is a check sum that's computed from the previous fifteen digits.\n",
    "* So there are about 20,000 BIN numbers and so if you do the calculation it turns out there are about 2 to the 42 possible credit card numbers which corresponds to about 42 bits of information that you need to encode if you want to represent a credit card number compactly. \n",
    "* So the question then is, again, can we have this mechanism called format preserving encryption, where encrypting a credit card itself produces something that looks like a credit card? So that's our goal. The encrypted credit card number should look like a regular valid credit card number.\n",
    "\n",
    "* In fact, it's gonna be, not exactly two to the 42. It's gonna be some funny numbers that's around two to the 42. And our goal is to build a PRP that acts exactly on the interval, zero to S minus one. And what we're given as input is some PRF, say, something like AES, that acts on much larger blocks, say, acts on sixteen byte blocks. So we're trying to, in some sense, shrink the domain of the PRF to make it fit the data that we're given. And the question is basically how to do that. Well, once we have such a construction we can easily use it to encrypt credit card numbers. What we would do is we would take the, a given credit card number. We would encode it such that now it's represented as a number between zero and the total number of credit card numbers. Then we would apply our PRP so we would encrypt this credit card number, you know, using construction number two from the deterministic encryption segment. And then we would map the final number back to be a regular, to look like val--, regular, valid credit card number and then send this along the way. So this is, this is again non expanding encryption. \n",
    "\n",
    "* **STEP 1**  From {0,1}^n to {0,1}^t (t < n)\n",
    "\n",
    "* So my goal is to show you how to construct this and once we see how to do it, you will also know how to encrypt credit card number so that the resulting cipher text is itself a credit card number. So the construction works in two steps. The first thing we do is we shrink our PRF from the set {0,1} to the n, say {0,1} to the 128 in the case of AES, to {0,1} to the t where t is the closest power of two to the value S. So say S is some crazy number around two to the 41. T would basically be then 42 because that's the closest power of two that's just above the value S. So the construction is basically gonna use the Luby-Rackoff construction. What we need is a PRF F prime that acts on blocks of size t over two. So imagine for example in the credit card case, t would be 42 because two to the 42 we said is the closest power of two that's bigger than, than, than S. S is the number of credit, total number of credit cards. Then we would need a PRF now that acts on 21-bit inputs. So one way to do that is simply to take the AES block cipher, treat it as a PRF on 128-bit inputs, and then simply truncate the output to the least significant 21 bits. Okay, so we were given a 21 bit value. We would append zeros to it so that we get 128 bits as a result. We would apply AES to that and then we would truncate back to 21 bits.\n",
    "\n",
    "* **STEP 2**\n",
    "\n",
    "* So step two will take us down from {0,1} to the T, to the actual set zero to the S minus one that we're interested in. And this construction is, again, really, really cute, so let me show you how it works. So, again, we're given this PRP that operates on a power of two. And we wanna go down to a PRP that operates on something slightly smaller. Okay, so here's on the construction works. Basically we're given input X in the set zero to S minus one that we want. And what we're going to do is we're going to iterate the following procedure again and again. So first of all we map X into this temporary variable Y. And now we're just gonna encrypt the input X and put the result into Y. If Y is inside of our target set, we stop and we output Y. If not we iterate this again and again and again and again and again until finally Y falls into our target set and then we output that value. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
